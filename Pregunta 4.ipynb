{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pregunta_4.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "yfMU2d_xUQ0C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pregunta  4"
      ]
    },
    {
      "metadata": {
        "id": "dw0zTBJRYLqx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Desde la edad antigua, múltiples formas de localización han sido desarrolladas. Dentro de los avances más importantes en este ámbito, es el desarrollo de la teorı́a cientı́fica y técnica denominada georreferenciación. Gracias a GPS, el crecimiento y acceso de la georreferenciación y navegación está en progresivo aumento, el problema surge cuando se intentan estimar en recintos interiores (como edificios o bajo tierra) donde el GPS no funciona de la manera como uno esperaría, debido a que existen muchos obstáculos e interferencia que imposibilitan su uso.\n",
        "Dentro de interiores se cuenta con señales RSSI (fingerprint) que pueden atacar este problema, sin embargo los métodos actuales no son robustos a ruido, por lo que su tarea será la de abordar este problema para mejorar exactitud de sistemas de posicionamiento en interiores mediante redes neuronales.\n",
        "\n",
        "La metodología con la que se trabajará será que, para dentro de interiores, dispositivos Bluetooth emiten señales RSSI las cuales son captadas por el dispositivo \"objetivo\" al cual se le desea determinar su localización, recibiendo distintas intensidades de señal de cada dispositivo emisor debido a su posición en el interior. Los datos con los que se va a trabajar (IndoorFingerprint.csv) fueron provistos por el nuevo Ing. Civil Informático Felipe Berrios, éstos constan de 8 características (C1hA,0kxZ,tvMX,OlYb,7rk5,F39L,VNSF,tkxI) correspondientes a las mediciones hechas/recibidas por el dispositivo \"objetivo\" de las distintas señales RSSI emitidas por los dispositivos Bluetooth en los bordes del interior, además de tener la posición del dispositivo \"objetivo\" en un plano XY (valor a estimar)."
      ]
    },
    {
      "metadata": {
        "id": "gLjvkcslWA3h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Una consideración importante es el cómo tratar la ausencia de la señal proveniente de un dispositivo Bluetooth, para estos datos se utiliza un valor de +100, ya que es imposible obtener este valor debido a las características de la escala RSSI (siempre negativa o igual a cero), pero puede ser sustituido por otro.\n",
        "Para hacer el trabajo mas simple se discretizará la posición en el plano definiendo zonas en dónde está el objeto a localizar. Las zonas deben ser las que indica la malla a continuación:"
      ]
    },
    {
      "metadata": {
        "id": "ewBKysrJXpDj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "acb8322d-cc01-4f6a-af09-45536c08714b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525439975669,
          "user_tz": 180,
          "elapsed": 25136,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e21f263e-96b7-4ffd-a7d0-902a6d743f90\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e21f263e-96b7-4ffd-a7d0-902a6d743f90\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving IndoorFingerprint.csv to IndoorFingerprint.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZDtbgwUTWTkG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "154b66ad-c17f-4bf7-d1ac-0de5c1a55e35",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525439987284,
          "user_tz": 180,
          "elapsed": 703,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import io #eliminar\n",
        "df = pd.read_csv(io.StringIO(uploaded[\"IndoorFingerprint.csv\"].decode('utf-8')))#\"./IndoorFingerprint.csv\")\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.scatter(df[\"X\"],df[\"Y\"])\n",
        "\n",
        "x_ticks = np.arange(0, 49, 8)\n",
        "y_ticks = np.arange(5, 22, 4)\n",
        "plt.xticks(x_ticks)\n",
        "plt.yticks(y_ticks)\n",
        "plt.grid(color='r', linestyle='-', linewidth=2)\n",
        "plt.ylabel(\"y position\")\n",
        "plt.xlabel(\"x position\")\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEKCAYAAADw2zkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f462aeeccc0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Rlq66LtoWo8Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Donde los puntos azules son los distintos datos superpuestos de las posiciones del objeto a localizar. Por ejemplo el punto (2,8) está en la primera zona (o en la primera zona del eje x y del eje y), el punto (2,20) está en la zona 19 (o en la primera zona del eje x y la cuarta zona del eje y). Esta discretización transforma el problema que en un principio podría ser de regresión para determinar la posición exacta, en un problema de clasificación dividiendo (dentro de los posibles valores) 6 zonas para el eje \"x\" y 4 zonas para el eje \"y\", contando con un total de 24 clases (24 zonas en la malla).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "0Q9fN77kUWqJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Se entrenará una red feed forward para la clasificación de las 24 posibles clases, donde tal red debe obtener un desempeño (accuracy) mayor al 75%.\n"
      ]
    },
    {
      "metadata": {
        "id": "qjIDu1CUYZ4h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A continuación se visualiza un resumen de los datos que se tienen como input, mediante la función *describe*.\n"
      ]
    },
    {
      "metadata": {
        "id": "5NPSE76xZyRC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "6a6c00b4-4784-4992-fce7-6cb1f1362b8b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525439991610,
          "user_tz": 180,
          "elapsed": 1382,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df.describe()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6600, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>C1hA</th>\n",
              "      <th>0kxZ</th>\n",
              "      <th>tvMX</th>\n",
              "      <th>OlYb</th>\n",
              "      <th>7rk5</th>\n",
              "      <th>F39L</th>\n",
              "      <th>VNSF</th>\n",
              "      <th>tkxI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6600.000000</td>\n",
              "      <td>6600.000000</td>\n",
              "      <td>6600.000000</td>\n",
              "      <td>6600.000000</td>\n",
              "      <td>6600.000000</td>\n",
              "      <td>6600.000000</td>\n",
              "      <td>6600.000000</td>\n",
              "      <td>6600.000000</td>\n",
              "      <td>6600.000000</td>\n",
              "      <td>6600.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>22.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>-71.152121</td>\n",
              "      <td>-85.025909</td>\n",
              "      <td>-89.734545</td>\n",
              "      <td>-77.810758</td>\n",
              "      <td>-90.219091</td>\n",
              "      <td>-80.133030</td>\n",
              "      <td>-89.091515</td>\n",
              "      <td>-89.195455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.650069</td>\n",
              "      <td>4.472475</td>\n",
              "      <td>61.117550</td>\n",
              "      <td>38.743163</td>\n",
              "      <td>7.763426</td>\n",
              "      <td>43.540421</td>\n",
              "      <td>9.230207</td>\n",
              "      <td>7.715085</td>\n",
              "      <td>7.296616</td>\n",
              "      <td>9.508659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>-105.000000</td>\n",
              "      <td>-104.000000</td>\n",
              "      <td>-107.000000</td>\n",
              "      <td>-103.000000</td>\n",
              "      <td>-105.000000</td>\n",
              "      <td>-102.000000</td>\n",
              "      <td>-102.000000</td>\n",
              "      <td>-105.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>-98.000000</td>\n",
              "      <td>-97.000000</td>\n",
              "      <td>-96.000000</td>\n",
              "      <td>-96.000000</td>\n",
              "      <td>-96.000000</td>\n",
              "      <td>-86.000000</td>\n",
              "      <td>-95.000000</td>\n",
              "      <td>-96.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>22.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>-93.000000</td>\n",
              "      <td>-94.000000</td>\n",
              "      <td>-92.000000</td>\n",
              "      <td>-87.000000</td>\n",
              "      <td>-91.000000</td>\n",
              "      <td>-80.000000</td>\n",
              "      <td>-90.000000</td>\n",
              "      <td>-90.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>34.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>-86.000000</td>\n",
              "      <td>-90.000000</td>\n",
              "      <td>-84.000000</td>\n",
              "      <td>-80.000000</td>\n",
              "      <td>-86.000000</td>\n",
              "      <td>-75.000000</td>\n",
              "      <td>-85.000000</td>\n",
              "      <td>-84.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>42.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>-65.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>-57.000000</td>\n",
              "      <td>-60.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 X            Y         C1hA         0kxZ         tvMX  \\\n",
              "count  6600.000000  6600.000000  6600.000000  6600.000000  6600.000000   \n",
              "mean     22.000000    14.000000   -71.152121   -85.025909   -89.734545   \n",
              "std      12.650069     4.472475    61.117550    38.743163     7.763426   \n",
              "min       2.000000     8.000000  -105.000000  -104.000000  -107.000000   \n",
              "25%      10.000000    11.000000   -98.000000   -97.000000   -96.000000   \n",
              "50%      22.000000    14.000000   -93.000000   -94.000000   -92.000000   \n",
              "75%      34.000000    17.000000   -86.000000   -90.000000   -84.000000   \n",
              "max      42.000000    20.000000   100.000000   100.000000   -65.000000   \n",
              "\n",
              "              OlYb         7rk5         F39L         VNSF         tkxI  \n",
              "count  6600.000000  6600.000000  6600.000000  6600.000000  6600.000000  \n",
              "mean    -77.810758   -90.219091   -80.133030   -89.091515   -89.195455  \n",
              "std      43.540421     9.230207     7.715085     7.296616     9.508659  \n",
              "min    -103.000000  -105.000000  -102.000000  -102.000000  -105.000000  \n",
              "25%     -96.000000   -96.000000   -86.000000   -95.000000   -96.000000  \n",
              "50%     -87.000000   -91.000000   -80.000000   -90.000000   -90.500000  \n",
              "75%     -80.000000   -86.000000   -75.000000   -85.000000   -84.000000  \n",
              "max     100.000000   100.000000   -57.000000   -60.000000   100.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "cj7GgyPyZTgg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "09a20d16-9764-4a47-abb5-2a8077341824",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525234226738,
          "user_tz": 180,
          "elapsed": 821,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>C1hA</th>\n",
              "      <th>0kxZ</th>\n",
              "      <th>tvMX</th>\n",
              "      <th>OlYb</th>\n",
              "      <th>7rk5</th>\n",
              "      <th>F39L</th>\n",
              "      <th>VNSF</th>\n",
              "      <th>tkxI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>-66</td>\n",
              "      <td>-92</td>\n",
              "      <td>-84</td>\n",
              "      <td>-84</td>\n",
              "      <td>-92</td>\n",
              "      <td>-93</td>\n",
              "      <td>-98</td>\n",
              "      <td>-96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>-66</td>\n",
              "      <td>-94</td>\n",
              "      <td>-84</td>\n",
              "      <td>-84</td>\n",
              "      <td>-94</td>\n",
              "      <td>-93</td>\n",
              "      <td>-98</td>\n",
              "      <td>-96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>-66</td>\n",
              "      <td>-94</td>\n",
              "      <td>-84</td>\n",
              "      <td>-84</td>\n",
              "      <td>-94</td>\n",
              "      <td>-93</td>\n",
              "      <td>-98</td>\n",
              "      <td>-100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>-66</td>\n",
              "      <td>-94</td>\n",
              "      <td>-84</td>\n",
              "      <td>-84</td>\n",
              "      <td>-94</td>\n",
              "      <td>-80</td>\n",
              "      <td>-98</td>\n",
              "      <td>-100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>-66</td>\n",
              "      <td>-94</td>\n",
              "      <td>-84</td>\n",
              "      <td>-84</td>\n",
              "      <td>-94</td>\n",
              "      <td>-74</td>\n",
              "      <td>-98</td>\n",
              "      <td>-100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     X    Y  C1hA  0kxZ  tvMX  OlYb  7rk5  F39L  VNSF  tkxI\n",
              "0  2.0  8.0   -66   -92   -84   -84   -92   -93   -98   -96\n",
              "1  2.0  8.0   -66   -94   -84   -84   -94   -93   -98   -96\n",
              "2  2.0  8.0   -66   -94   -84   -84   -94   -93   -98  -100\n",
              "3  2.0  8.0   -66   -94   -84   -84   -94   -80   -98  -100\n",
              "4  2.0  8.0   -66   -94   -84   -84   -94   -74   -98  -100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "nrNnYFK4cJLG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A continuación se genera el conjunto de entrenamiento y de pruebas. Primero se lee el archivo 'mask_test.csv', el cual indica los indices de las posiciones en el dataset que conforman el conjunto de pruebas."
      ]
    },
    {
      "metadata": {
        "id": "qn8zTU-NdgDJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0a1f483d-18e7-4e0f-b7a1-13e285da577a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525440001751,
          "user_tz": 180,
          "elapsed": 6731,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a1f3b92e-efe0-4f7f-805f-63c456258ba1\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a1f3b92e-efe0-4f7f-805f-63c456258ba1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving mask_test.csv to mask_test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-cR_C6lmdGEA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mask_test = np.loadtxt('mask_test.csv',dtype=\"i\")\n",
        "X = df.as_matrix()\n",
        "#X_test = X[mask_test]\n",
        "#X_train = np.delete(X,mask_test,axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hnFt0M6ZnDgn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38f5c82f-b510-4dc9-d999-9b567784d7a0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525440009653,
          "user_tz": 180,
          "elapsed": 846,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6600, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "BIlRkxetokIX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aed031e6-4a7a-4e53-c254-3693f8cb3858",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525440011352,
          "user_tz": 180,
          "elapsed": 666,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(X))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kEtlxqWXmgDs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Luego, se identifica en qué posición de la grilla se encuentra cada punto, según la variable *X* e *Y* del dataset original, las cuales se comparan con *x_ticks* e *y_ticks*, respectivamente."
      ]
    },
    {
      "metadata": {
        "id": "kzT9C5TYnl3w",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "762d64ad-1e97-4818-a0f8-7abd45fa4898",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525440014119,
          "user_tz": 180,
          "elapsed": 635,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.where(y_ticks>20)[0][0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "ZjnxBIELme1A",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "n = 24\n",
        "posiciones_grilla = []\n",
        "for i in X:\n",
        "  #print(i[0], i[1])\n",
        "  x = np.where(x_ticks>i[0])[0][0]\n",
        "  y = np.where(y_ticks>i[1])[0][0]\n",
        "  posiciones_grilla.append((x,y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xHcpIhALpL3Y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b0b892de-5221-4230-ed81-250f2277f07c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525440019316,
          "user_tz": 180,
          "elapsed": 675,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(posiciones_grilla)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (5, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 1), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (6, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (5, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (4, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (3, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (2, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (4, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (5, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 3), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (6, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (5, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (4, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (3, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4), (1, 4)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NBFhPwKMYrVJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Luego, cada posición para el ejemplo entregado es transformado en un one-hot vector, mediante la funcipón *get_dummies* de *pandas*."
      ]
    },
    {
      "metadata": {
        "id": "oeH72sbW0kZg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "y_labels = pd.get_dummies(posiciones_grilla)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y8EC2OqB0rO-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 6477
        },
        "outputId": "40a47257-72b7-4e16-ec04-95bc0f627007",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525440023503,
          "user_tz": 180,
          "elapsed": 762,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(y_labels.head)\n",
        "y_labels.tail"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of       (1, 1)  (1, 2)  (1, 3)  (1, 4)  (2, 1)  (2, 2)  (2, 3)  (2, 4)  (3, 1)  \\\n",
            "0          1       0       0       0       0       0       0       0       0   \n",
            "1          1       0       0       0       0       0       0       0       0   \n",
            "2          1       0       0       0       0       0       0       0       0   \n",
            "3          1       0       0       0       0       0       0       0       0   \n",
            "4          1       0       0       0       0       0       0       0       0   \n",
            "5          1       0       0       0       0       0       0       0       0   \n",
            "6          1       0       0       0       0       0       0       0       0   \n",
            "7          1       0       0       0       0       0       0       0       0   \n",
            "8          1       0       0       0       0       0       0       0       0   \n",
            "9          1       0       0       0       0       0       0       0       0   \n",
            "10         1       0       0       0       0       0       0       0       0   \n",
            "11         1       0       0       0       0       0       0       0       0   \n",
            "12         1       0       0       0       0       0       0       0       0   \n",
            "13         1       0       0       0       0       0       0       0       0   \n",
            "14         1       0       0       0       0       0       0       0       0   \n",
            "15         1       0       0       0       0       0       0       0       0   \n",
            "16         1       0       0       0       0       0       0       0       0   \n",
            "17         1       0       0       0       0       0       0       0       0   \n",
            "18         1       0       0       0       0       0       0       0       0   \n",
            "19         1       0       0       0       0       0       0       0       0   \n",
            "20         1       0       0       0       0       0       0       0       0   \n",
            "21         1       0       0       0       0       0       0       0       0   \n",
            "22         1       0       0       0       0       0       0       0       0   \n",
            "23         1       0       0       0       0       0       0       0       0   \n",
            "24         1       0       0       0       0       0       0       0       0   \n",
            "25         1       0       0       0       0       0       0       0       0   \n",
            "26         1       0       0       0       0       0       0       0       0   \n",
            "27         1       0       0       0       0       0       0       0       0   \n",
            "28         1       0       0       0       0       0       0       0       0   \n",
            "29         1       0       0       0       0       0       0       0       0   \n",
            "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
            "6570       0       0       0       1       0       0       0       0       0   \n",
            "6571       0       0       0       1       0       0       0       0       0   \n",
            "6572       0       0       0       1       0       0       0       0       0   \n",
            "6573       0       0       0       1       0       0       0       0       0   \n",
            "6574       0       0       0       1       0       0       0       0       0   \n",
            "6575       0       0       0       1       0       0       0       0       0   \n",
            "6576       0       0       0       1       0       0       0       0       0   \n",
            "6577       0       0       0       1       0       0       0       0       0   \n",
            "6578       0       0       0       1       0       0       0       0       0   \n",
            "6579       0       0       0       1       0       0       0       0       0   \n",
            "6580       0       0       0       1       0       0       0       0       0   \n",
            "6581       0       0       0       1       0       0       0       0       0   \n",
            "6582       0       0       0       1       0       0       0       0       0   \n",
            "6583       0       0       0       1       0       0       0       0       0   \n",
            "6584       0       0       0       1       0       0       0       0       0   \n",
            "6585       0       0       0       1       0       0       0       0       0   \n",
            "6586       0       0       0       1       0       0       0       0       0   \n",
            "6587       0       0       0       1       0       0       0       0       0   \n",
            "6588       0       0       0       1       0       0       0       0       0   \n",
            "6589       0       0       0       1       0       0       0       0       0   \n",
            "6590       0       0       0       1       0       0       0       0       0   \n",
            "6591       0       0       0       1       0       0       0       0       0   \n",
            "6592       0       0       0       1       0       0       0       0       0   \n",
            "6593       0       0       0       1       0       0       0       0       0   \n",
            "6594       0       0       0       1       0       0       0       0       0   \n",
            "6595       0       0       0       1       0       0       0       0       0   \n",
            "6596       0       0       0       1       0       0       0       0       0   \n",
            "6597       0       0       0       1       0       0       0       0       0   \n",
            "6598       0       0       0       1       0       0       0       0       0   \n",
            "6599       0       0       0       1       0       0       0       0       0   \n",
            "\n",
            "      (3, 2)   ...    (4, 3)  (4, 4)  (5, 1)  (5, 2)  (5, 3)  (5, 4)  (6, 1)  \\\n",
            "0          0   ...         0       0       0       0       0       0       0   \n",
            "1          0   ...         0       0       0       0       0       0       0   \n",
            "2          0   ...         0       0       0       0       0       0       0   \n",
            "3          0   ...         0       0       0       0       0       0       0   \n",
            "4          0   ...         0       0       0       0       0       0       0   \n",
            "5          0   ...         0       0       0       0       0       0       0   \n",
            "6          0   ...         0       0       0       0       0       0       0   \n",
            "7          0   ...         0       0       0       0       0       0       0   \n",
            "8          0   ...         0       0       0       0       0       0       0   \n",
            "9          0   ...         0       0       0       0       0       0       0   \n",
            "10         0   ...         0       0       0       0       0       0       0   \n",
            "11         0   ...         0       0       0       0       0       0       0   \n",
            "12         0   ...         0       0       0       0       0       0       0   \n",
            "13         0   ...         0       0       0       0       0       0       0   \n",
            "14         0   ...         0       0       0       0       0       0       0   \n",
            "15         0   ...         0       0       0       0       0       0       0   \n",
            "16         0   ...         0       0       0       0       0       0       0   \n",
            "17         0   ...         0       0       0       0       0       0       0   \n",
            "18         0   ...         0       0       0       0       0       0       0   \n",
            "19         0   ...         0       0       0       0       0       0       0   \n",
            "20         0   ...         0       0       0       0       0       0       0   \n",
            "21         0   ...         0       0       0       0       0       0       0   \n",
            "22         0   ...         0       0       0       0       0       0       0   \n",
            "23         0   ...         0       0       0       0       0       0       0   \n",
            "24         0   ...         0       0       0       0       0       0       0   \n",
            "25         0   ...         0       0       0       0       0       0       0   \n",
            "26         0   ...         0       0       0       0       0       0       0   \n",
            "27         0   ...         0       0       0       0       0       0       0   \n",
            "28         0   ...         0       0       0       0       0       0       0   \n",
            "29         0   ...         0       0       0       0       0       0       0   \n",
            "...      ...   ...       ...     ...     ...     ...     ...     ...     ...   \n",
            "6570       0   ...         0       0       0       0       0       0       0   \n",
            "6571       0   ...         0       0       0       0       0       0       0   \n",
            "6572       0   ...         0       0       0       0       0       0       0   \n",
            "6573       0   ...         0       0       0       0       0       0       0   \n",
            "6574       0   ...         0       0       0       0       0       0       0   \n",
            "6575       0   ...         0       0       0       0       0       0       0   \n",
            "6576       0   ...         0       0       0       0       0       0       0   \n",
            "6577       0   ...         0       0       0       0       0       0       0   \n",
            "6578       0   ...         0       0       0       0       0       0       0   \n",
            "6579       0   ...         0       0       0       0       0       0       0   \n",
            "6580       0   ...         0       0       0       0       0       0       0   \n",
            "6581       0   ...         0       0       0       0       0       0       0   \n",
            "6582       0   ...         0       0       0       0       0       0       0   \n",
            "6583       0   ...         0       0       0       0       0       0       0   \n",
            "6584       0   ...         0       0       0       0       0       0       0   \n",
            "6585       0   ...         0       0       0       0       0       0       0   \n",
            "6586       0   ...         0       0       0       0       0       0       0   \n",
            "6587       0   ...         0       0       0       0       0       0       0   \n",
            "6588       0   ...         0       0       0       0       0       0       0   \n",
            "6589       0   ...         0       0       0       0       0       0       0   \n",
            "6590       0   ...         0       0       0       0       0       0       0   \n",
            "6591       0   ...         0       0       0       0       0       0       0   \n",
            "6592       0   ...         0       0       0       0       0       0       0   \n",
            "6593       0   ...         0       0       0       0       0       0       0   \n",
            "6594       0   ...         0       0       0       0       0       0       0   \n",
            "6595       0   ...         0       0       0       0       0       0       0   \n",
            "6596       0   ...         0       0       0       0       0       0       0   \n",
            "6597       0   ...         0       0       0       0       0       0       0   \n",
            "6598       0   ...         0       0       0       0       0       0       0   \n",
            "6599       0   ...         0       0       0       0       0       0       0   \n",
            "\n",
            "      (6, 2)  (6, 3)  (6, 4)  \n",
            "0          0       0       0  \n",
            "1          0       0       0  \n",
            "2          0       0       0  \n",
            "3          0       0       0  \n",
            "4          0       0       0  \n",
            "5          0       0       0  \n",
            "6          0       0       0  \n",
            "7          0       0       0  \n",
            "8          0       0       0  \n",
            "9          0       0       0  \n",
            "10         0       0       0  \n",
            "11         0       0       0  \n",
            "12         0       0       0  \n",
            "13         0       0       0  \n",
            "14         0       0       0  \n",
            "15         0       0       0  \n",
            "16         0       0       0  \n",
            "17         0       0       0  \n",
            "18         0       0       0  \n",
            "19         0       0       0  \n",
            "20         0       0       0  \n",
            "21         0       0       0  \n",
            "22         0       0       0  \n",
            "23         0       0       0  \n",
            "24         0       0       0  \n",
            "25         0       0       0  \n",
            "26         0       0       0  \n",
            "27         0       0       0  \n",
            "28         0       0       0  \n",
            "29         0       0       0  \n",
            "...      ...     ...     ...  \n",
            "6570       0       0       0  \n",
            "6571       0       0       0  \n",
            "6572       0       0       0  \n",
            "6573       0       0       0  \n",
            "6574       0       0       0  \n",
            "6575       0       0       0  \n",
            "6576       0       0       0  \n",
            "6577       0       0       0  \n",
            "6578       0       0       0  \n",
            "6579       0       0       0  \n",
            "6580       0       0       0  \n",
            "6581       0       0       0  \n",
            "6582       0       0       0  \n",
            "6583       0       0       0  \n",
            "6584       0       0       0  \n",
            "6585       0       0       0  \n",
            "6586       0       0       0  \n",
            "6587       0       0       0  \n",
            "6588       0       0       0  \n",
            "6589       0       0       0  \n",
            "6590       0       0       0  \n",
            "6591       0       0       0  \n",
            "6592       0       0       0  \n",
            "6593       0       0       0  \n",
            "6594       0       0       0  \n",
            "6595       0       0       0  \n",
            "6596       0       0       0  \n",
            "6597       0       0       0  \n",
            "6598       0       0       0  \n",
            "6599       0       0       0  \n",
            "\n",
            "[6600 rows x 24 columns]>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.tail of       (1, 1)  (1, 2)  (1, 3)  (1, 4)  (2, 1)  (2, 2)  (2, 3)  (2, 4)  (3, 1)  \\\n",
              "0          1       0       0       0       0       0       0       0       0   \n",
              "1          1       0       0       0       0       0       0       0       0   \n",
              "2          1       0       0       0       0       0       0       0       0   \n",
              "3          1       0       0       0       0       0       0       0       0   \n",
              "4          1       0       0       0       0       0       0       0       0   \n",
              "5          1       0       0       0       0       0       0       0       0   \n",
              "6          1       0       0       0       0       0       0       0       0   \n",
              "7          1       0       0       0       0       0       0       0       0   \n",
              "8          1       0       0       0       0       0       0       0       0   \n",
              "9          1       0       0       0       0       0       0       0       0   \n",
              "10         1       0       0       0       0       0       0       0       0   \n",
              "11         1       0       0       0       0       0       0       0       0   \n",
              "12         1       0       0       0       0       0       0       0       0   \n",
              "13         1       0       0       0       0       0       0       0       0   \n",
              "14         1       0       0       0       0       0       0       0       0   \n",
              "15         1       0       0       0       0       0       0       0       0   \n",
              "16         1       0       0       0       0       0       0       0       0   \n",
              "17         1       0       0       0       0       0       0       0       0   \n",
              "18         1       0       0       0       0       0       0       0       0   \n",
              "19         1       0       0       0       0       0       0       0       0   \n",
              "20         1       0       0       0       0       0       0       0       0   \n",
              "21         1       0       0       0       0       0       0       0       0   \n",
              "22         1       0       0       0       0       0       0       0       0   \n",
              "23         1       0       0       0       0       0       0       0       0   \n",
              "24         1       0       0       0       0       0       0       0       0   \n",
              "25         1       0       0       0       0       0       0       0       0   \n",
              "26         1       0       0       0       0       0       0       0       0   \n",
              "27         1       0       0       0       0       0       0       0       0   \n",
              "28         1       0       0       0       0       0       0       0       0   \n",
              "29         1       0       0       0       0       0       0       0       0   \n",
              "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "6570       0       0       0       1       0       0       0       0       0   \n",
              "6571       0       0       0       1       0       0       0       0       0   \n",
              "6572       0       0       0       1       0       0       0       0       0   \n",
              "6573       0       0       0       1       0       0       0       0       0   \n",
              "6574       0       0       0       1       0       0       0       0       0   \n",
              "6575       0       0       0       1       0       0       0       0       0   \n",
              "6576       0       0       0       1       0       0       0       0       0   \n",
              "6577       0       0       0       1       0       0       0       0       0   \n",
              "6578       0       0       0       1       0       0       0       0       0   \n",
              "6579       0       0       0       1       0       0       0       0       0   \n",
              "6580       0       0       0       1       0       0       0       0       0   \n",
              "6581       0       0       0       1       0       0       0       0       0   \n",
              "6582       0       0       0       1       0       0       0       0       0   \n",
              "6583       0       0       0       1       0       0       0       0       0   \n",
              "6584       0       0       0       1       0       0       0       0       0   \n",
              "6585       0       0       0       1       0       0       0       0       0   \n",
              "6586       0       0       0       1       0       0       0       0       0   \n",
              "6587       0       0       0       1       0       0       0       0       0   \n",
              "6588       0       0       0       1       0       0       0       0       0   \n",
              "6589       0       0       0       1       0       0       0       0       0   \n",
              "6590       0       0       0       1       0       0       0       0       0   \n",
              "6591       0       0       0       1       0       0       0       0       0   \n",
              "6592       0       0       0       1       0       0       0       0       0   \n",
              "6593       0       0       0       1       0       0       0       0       0   \n",
              "6594       0       0       0       1       0       0       0       0       0   \n",
              "6595       0       0       0       1       0       0       0       0       0   \n",
              "6596       0       0       0       1       0       0       0       0       0   \n",
              "6597       0       0       0       1       0       0       0       0       0   \n",
              "6598       0       0       0       1       0       0       0       0       0   \n",
              "6599       0       0       0       1       0       0       0       0       0   \n",
              "\n",
              "      (3, 2)   ...    (4, 3)  (4, 4)  (5, 1)  (5, 2)  (5, 3)  (5, 4)  (6, 1)  \\\n",
              "0          0   ...         0       0       0       0       0       0       0   \n",
              "1          0   ...         0       0       0       0       0       0       0   \n",
              "2          0   ...         0       0       0       0       0       0       0   \n",
              "3          0   ...         0       0       0       0       0       0       0   \n",
              "4          0   ...         0       0       0       0       0       0       0   \n",
              "5          0   ...         0       0       0       0       0       0       0   \n",
              "6          0   ...         0       0       0       0       0       0       0   \n",
              "7          0   ...         0       0       0       0       0       0       0   \n",
              "8          0   ...         0       0       0       0       0       0       0   \n",
              "9          0   ...         0       0       0       0       0       0       0   \n",
              "10         0   ...         0       0       0       0       0       0       0   \n",
              "11         0   ...         0       0       0       0       0       0       0   \n",
              "12         0   ...         0       0       0       0       0       0       0   \n",
              "13         0   ...         0       0       0       0       0       0       0   \n",
              "14         0   ...         0       0       0       0       0       0       0   \n",
              "15         0   ...         0       0       0       0       0       0       0   \n",
              "16         0   ...         0       0       0       0       0       0       0   \n",
              "17         0   ...         0       0       0       0       0       0       0   \n",
              "18         0   ...         0       0       0       0       0       0       0   \n",
              "19         0   ...         0       0       0       0       0       0       0   \n",
              "20         0   ...         0       0       0       0       0       0       0   \n",
              "21         0   ...         0       0       0       0       0       0       0   \n",
              "22         0   ...         0       0       0       0       0       0       0   \n",
              "23         0   ...         0       0       0       0       0       0       0   \n",
              "24         0   ...         0       0       0       0       0       0       0   \n",
              "25         0   ...         0       0       0       0       0       0       0   \n",
              "26         0   ...         0       0       0       0       0       0       0   \n",
              "27         0   ...         0       0       0       0       0       0       0   \n",
              "28         0   ...         0       0       0       0       0       0       0   \n",
              "29         0   ...         0       0       0       0       0       0       0   \n",
              "...      ...   ...       ...     ...     ...     ...     ...     ...     ...   \n",
              "6570       0   ...         0       0       0       0       0       0       0   \n",
              "6571       0   ...         0       0       0       0       0       0       0   \n",
              "6572       0   ...         0       0       0       0       0       0       0   \n",
              "6573       0   ...         0       0       0       0       0       0       0   \n",
              "6574       0   ...         0       0       0       0       0       0       0   \n",
              "6575       0   ...         0       0       0       0       0       0       0   \n",
              "6576       0   ...         0       0       0       0       0       0       0   \n",
              "6577       0   ...         0       0       0       0       0       0       0   \n",
              "6578       0   ...         0       0       0       0       0       0       0   \n",
              "6579       0   ...         0       0       0       0       0       0       0   \n",
              "6580       0   ...         0       0       0       0       0       0       0   \n",
              "6581       0   ...         0       0       0       0       0       0       0   \n",
              "6582       0   ...         0       0       0       0       0       0       0   \n",
              "6583       0   ...         0       0       0       0       0       0       0   \n",
              "6584       0   ...         0       0       0       0       0       0       0   \n",
              "6585       0   ...         0       0       0       0       0       0       0   \n",
              "6586       0   ...         0       0       0       0       0       0       0   \n",
              "6587       0   ...         0       0       0       0       0       0       0   \n",
              "6588       0   ...         0       0       0       0       0       0       0   \n",
              "6589       0   ...         0       0       0       0       0       0       0   \n",
              "6590       0   ...         0       0       0       0       0       0       0   \n",
              "6591       0   ...         0       0       0       0       0       0       0   \n",
              "6592       0   ...         0       0       0       0       0       0       0   \n",
              "6593       0   ...         0       0       0       0       0       0       0   \n",
              "6594       0   ...         0       0       0       0       0       0       0   \n",
              "6595       0   ...         0       0       0       0       0       0       0   \n",
              "6596       0   ...         0       0       0       0       0       0       0   \n",
              "6597       0   ...         0       0       0       0       0       0       0   \n",
              "6598       0   ...         0       0       0       0       0       0       0   \n",
              "6599       0   ...         0       0       0       0       0       0       0   \n",
              "\n",
              "      (6, 2)  (6, 3)  (6, 4)  \n",
              "0          0       0       0  \n",
              "1          0       0       0  \n",
              "2          0       0       0  \n",
              "3          0       0       0  \n",
              "4          0       0       0  \n",
              "5          0       0       0  \n",
              "6          0       0       0  \n",
              "7          0       0       0  \n",
              "8          0       0       0  \n",
              "9          0       0       0  \n",
              "10         0       0       0  \n",
              "11         0       0       0  \n",
              "12         0       0       0  \n",
              "13         0       0       0  \n",
              "14         0       0       0  \n",
              "15         0       0       0  \n",
              "16         0       0       0  \n",
              "17         0       0       0  \n",
              "18         0       0       0  \n",
              "19         0       0       0  \n",
              "20         0       0       0  \n",
              "21         0       0       0  \n",
              "22         0       0       0  \n",
              "23         0       0       0  \n",
              "24         0       0       0  \n",
              "25         0       0       0  \n",
              "26         0       0       0  \n",
              "27         0       0       0  \n",
              "28         0       0       0  \n",
              "29         0       0       0  \n",
              "...      ...     ...     ...  \n",
              "6570       0       0       0  \n",
              "6571       0       0       0  \n",
              "6572       0       0       0  \n",
              "6573       0       0       0  \n",
              "6574       0       0       0  \n",
              "6575       0       0       0  \n",
              "6576       0       0       0  \n",
              "6577       0       0       0  \n",
              "6578       0       0       0  \n",
              "6579       0       0       0  \n",
              "6580       0       0       0  \n",
              "6581       0       0       0  \n",
              "6582       0       0       0  \n",
              "6583       0       0       0  \n",
              "6584       0       0       0  \n",
              "6585       0       0       0  \n",
              "6586       0       0       0  \n",
              "6587       0       0       0  \n",
              "6588       0       0       0  \n",
              "6589       0       0       0  \n",
              "6590       0       0       0  \n",
              "6591       0       0       0  \n",
              "6592       0       0       0  \n",
              "6593       0       0       0  \n",
              "6594       0       0       0  \n",
              "6595       0       0       0  \n",
              "6596       0       0       0  \n",
              "6597       0       0       0  \n",
              "6598       0       0       0  \n",
              "6599       0       0       0  \n",
              "\n",
              "[6600 rows x 24 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "e1ZjY1W3YwCG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Luego, se deben eliminar las columnas *X* e *Y* de los datos, ya que estos indican la posición en el espacio, el cual fue trabajado anteriormente, y corresponde a la etiqueta a predecir, es decir, en qué posición de la grilla estará cierto input. Ahora, después de todo este preprocesamiento de los datos se pueden generar el conjunto de entrenamiento y de prueba."
      ]
    },
    {
      "metadata": {
        "id": "HzytuNVWAnEe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "df.drop([\"X\",\"Y\"],axis=1,inplace=True)\n",
        "X = df.as_matrix()\n",
        "X_test = X[mask_test]\n",
        "X_train = np.delete(X,mask_test,axis=0)\n",
        "\n",
        "Y = y_labels.as_matrix()\n",
        "Y_test = Y[mask_test]\n",
        "Y_train = np.delete(Y,mask_test,axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R2dDUGV_CV8r",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c592eae3-6bfa-4236-b051-4828c3487c98",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525440029283,
          "user_tz": 180,
          "elapsed": 845,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(X_train)+len(X_test))\n",
        "print(len(Y_train)+len(Y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6600\n",
            "6600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Jszm9CtY0Ja",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Como se vio anteriormente todos los datos viven en diferentes rangos y con distintas estadísticas como media y varianza, lo cual podría traer problemas numéricos. Por lo tanto, se normaliza el conjunto de input de enrenamiento y de prueba."
      ]
    },
    {
      "metadata": {
        "id": "LP1mn5DEDYIM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b928a0a9-1a7c-4c2d-d393-cd8370ebfe6a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525440035850,
          "user_tz": 180,
          "elapsed": 1117,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "E7C18SSbFK1F",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2a30e00d-01f0-49ff-a997-ff0ed094e03c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525440040338,
          "user_tz": 180,
          "elapsed": 682,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "scaler_test = StandardScaler().fit(X_test)\n",
        "X_test_scaled = scaler_test.transform(X_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "WHw2CpvtDfAS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.optimizers import SGD, rmsprop\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.utils import plot_model\n",
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6B2sC4znHbWP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a4f1167-63d8-4252-8f94-d6eab05eb525",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525440737052,
          "user_tz": 180,
          "elapsed": 638,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(X_train.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4620, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qz7M4r-lY6Q2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " A continuación se entrega una red neuronal feed forward:\n",
        " * Primera capa: 200 neuronas\n",
        " * Primera capa oculta: 400 neuronas\n",
        " * Segunda capa oculta: 200 neuronas \n",
        " * Capa de salida: 24 neuronas\n",
        " * Función de activación ReLU, excepto para la capa de salida que es Softmax\n",
        " * Inicialización de pesos: uniforme\n",
        " * Función de pérdida: Categorical cross entropy\n",
        " * Optimizador: SGD\n",
        " * Tasa de aprendizaje: 0.001\n",
        " * Epochs: 300"
      ]
    },
    {
      "metadata": {
        "id": "tLvcmqtWEtri",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "b69d4967-09eb-41e2-bdda-74ad02b3c526",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525440070227,
          "user_tz": 180,
          "elapsed": 859,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(200, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(400, kernel_initializer='uniform'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(200))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(24, activation='softmax'))\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 200)               1800      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 400)               80400     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 200)               80200     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 24)                4824      \n",
            "=================================================================\n",
            "Total params: 167,224\n",
            "Trainable params: 167,224\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l6uZv60_ItTb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sgd = SGD(lr=0.001)\n",
        "model.compile(optimizer=sgd,loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mYyV-VZiJEPn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 10254
        },
        "outputId": "6edbc9b1-4b76-4a01-ea05-a49cef50fe6c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525440378012,
          "user_tz": 180,
          "elapsed": 279533,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model_fit = model.fit(X_train_scaled, Y_train, epochs=300, verbose=1, validation_data=(X_test_scaled, Y_test), shuffle=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4620 samples, validate on 1980 samples\n",
            "Epoch 1/300\n",
            "4620/4620 [==============================] - 2s 401us/step - loss: 3.1769 - acc: 0.0288 - val_loss: 3.1749 - val_acc: 0.0424\n",
            "Epoch 2/300\n",
            "4620/4620 [==============================] - 1s 178us/step - loss: 3.1730 - acc: 0.0792 - val_loss: 3.1710 - val_acc: 0.0894\n",
            "Epoch 3/300\n",
            "4620/4620 [==============================] - 1s 204us/step - loss: 3.1690 - acc: 0.1435 - val_loss: 3.1671 - val_acc: 0.1540\n",
            "Epoch 4/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 3.1652 - acc: 0.1764 - val_loss: 3.1634 - val_acc: 0.1793\n",
            "Epoch 5/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 3.1615 - acc: 0.2028 - val_loss: 3.1598 - val_acc: 0.2076\n",
            "Epoch 6/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 3.1580 - acc: 0.2273 - val_loss: 3.1564 - val_acc: 0.2247\n",
            "Epoch 7/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 3.1547 - acc: 0.2377 - val_loss: 3.1530 - val_acc: 0.2303\n",
            "Epoch 8/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 3.1514 - acc: 0.2450 - val_loss: 3.1498 - val_acc: 0.2313\n",
            "Epoch 9/300\n",
            "3968/4620 [========================>.....] - ETA: 0s - loss: 3.1481 - acc: 0.2482"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 201us/step - loss: 3.1481 - acc: 0.2485 - val_loss: 3.1465 - val_acc: 0.2328\n",
            "Epoch 10/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 3.1448 - acc: 0.2474 - val_loss: 3.1432 - val_acc: 0.2323\n",
            "Epoch 11/300\n",
            "4620/4620 [==============================] - 1s 206us/step - loss: 3.1415 - acc: 0.2481 - val_loss: 3.1398 - val_acc: 0.2328\n",
            "Epoch 12/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 3.1381 - acc: 0.2474 - val_loss: 3.1364 - val_acc: 0.2364\n",
            "Epoch 13/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 3.1347 - acc: 0.2513 - val_loss: 3.1329 - val_acc: 0.2354\n",
            "Epoch 14/300\n",
            "4620/4620 [==============================] - 1s 204us/step - loss: 3.1312 - acc: 0.2541 - val_loss: 3.1294 - val_acc: 0.2379\n",
            "Epoch 15/300\n",
            "4620/4620 [==============================] - 1s 208us/step - loss: 3.1276 - acc: 0.2545 - val_loss: 3.1257 - val_acc: 0.2424\n",
            "Epoch 16/300\n",
            "4620/4620 [==============================] - 1s 205us/step - loss: 3.1239 - acc: 0.2584 - val_loss: 3.1220 - val_acc: 0.2470\n",
            "Epoch 17/300\n",
            "4620/4620 [==============================] - 1s 205us/step - loss: 3.1202 - acc: 0.2617 - val_loss: 3.1182 - val_acc: 0.2525\n",
            "Epoch 18/300\n",
            " 352/4620 [=>............................] - ETA: 0s - loss: 3.1195 - acc: 0.2528"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 205us/step - loss: 3.1163 - acc: 0.2684 - val_loss: 3.1143 - val_acc: 0.2581\n",
            "Epoch 19/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 3.1123 - acc: 0.2779 - val_loss: 3.1102 - val_acc: 0.2626\n",
            "Epoch 20/300\n",
            "4620/4620 [==============================] - 1s 206us/step - loss: 3.1083 - acc: 0.2851 - val_loss: 3.1061 - val_acc: 0.2737\n",
            "Epoch 21/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 3.1041 - acc: 0.2961 - val_loss: 3.1018 - val_acc: 0.2823\n",
            "Epoch 22/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 3.0997 - acc: 0.3054 - val_loss: 3.0974 - val_acc: 0.2929\n",
            "Epoch 23/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 3.0953 - acc: 0.3160 - val_loss: 3.0929 - val_acc: 0.3056\n",
            "Epoch 24/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 3.0907 - acc: 0.3227 - val_loss: 3.0883 - val_acc: 0.3131\n",
            "Epoch 25/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 3.0860 - acc: 0.3307 - val_loss: 3.0835 - val_acc: 0.3162\n",
            "Epoch 26/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 3.0811 - acc: 0.3379 - val_loss: 3.0785 - val_acc: 0.3202\n",
            "Epoch 27/300\n",
            " 928/4620 [=====>........................] - ETA: 0s - loss: 3.0743 - acc: 0.3330"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 199us/step - loss: 3.0760 - acc: 0.3422 - val_loss: 3.0734 - val_acc: 0.3237\n",
            "Epoch 28/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 3.0708 - acc: 0.3420 - val_loss: 3.0680 - val_acc: 0.3258\n",
            "Epoch 29/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 3.0654 - acc: 0.3448 - val_loss: 3.0624 - val_acc: 0.3288\n",
            "Epoch 30/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 3.0597 - acc: 0.3496 - val_loss: 3.0567 - val_acc: 0.3323\n",
            "Epoch 31/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 3.0538 - acc: 0.3522 - val_loss: 3.0507 - val_acc: 0.3354\n",
            "Epoch 32/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 3.0477 - acc: 0.3545 - val_loss: 3.0444 - val_acc: 0.3384\n",
            "Epoch 33/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 3.0413 - acc: 0.3576 - val_loss: 3.0379 - val_acc: 0.3419\n",
            "Epoch 34/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 3.0346 - acc: 0.3600 - val_loss: 3.0311 - val_acc: 0.3424\n",
            "Epoch 35/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 3.0277 - acc: 0.3619 - val_loss: 3.0240 - val_acc: 0.3449\n",
            "Epoch 36/300\n",
            " 928/4620 [=====>........................] - ETA: 0s - loss: 3.0228 - acc: 0.3470"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 203us/step - loss: 3.0204 - acc: 0.3628 - val_loss: 3.0166 - val_acc: 0.3470\n",
            "Epoch 37/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 3.0128 - acc: 0.3641 - val_loss: 3.0088 - val_acc: 0.3505\n",
            "Epoch 38/300\n",
            "4620/4620 [==============================] - 1s 204us/step - loss: 3.0049 - acc: 0.3665 - val_loss: 3.0007 - val_acc: 0.3510\n",
            "Epoch 39/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 2.9965 - acc: 0.3682 - val_loss: 2.9922 - val_acc: 0.3520\n",
            "Epoch 40/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 2.9878 - acc: 0.3706 - val_loss: 2.9832 - val_acc: 0.3540\n",
            "Epoch 41/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 2.9786 - acc: 0.3699 - val_loss: 2.9738 - val_acc: 0.3551\n",
            "Epoch 42/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 2.9689 - acc: 0.3703 - val_loss: 2.9639 - val_acc: 0.3540\n",
            "Epoch 43/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 2.9588 - acc: 0.3721 - val_loss: 2.9536 - val_acc: 0.3545\n",
            "Epoch 44/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 2.9481 - acc: 0.3719 - val_loss: 2.9427 - val_acc: 0.3556\n",
            "Epoch 45/300\n",
            "1216/4620 [======>.......................] - ETA: 0s - loss: 2.9412 - acc: 0.3882"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 199us/step - loss: 2.9370 - acc: 0.3699 - val_loss: 2.9313 - val_acc: 0.3571\n",
            "Epoch 46/300\n",
            "4620/4620 [==============================] - 1s 197us/step - loss: 2.9253 - acc: 0.3708 - val_loss: 2.9194 - val_acc: 0.3581\n",
            "Epoch 47/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 2.9131 - acc: 0.3703 - val_loss: 2.9069 - val_acc: 0.3561\n",
            "Epoch 48/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 2.9002 - acc: 0.3688 - val_loss: 2.8937 - val_acc: 0.3545\n",
            "Epoch 49/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 2.8866 - acc: 0.3671 - val_loss: 2.8799 - val_acc: 0.3566\n",
            "Epoch 50/300\n",
            "4620/4620 [==============================] - 1s 204us/step - loss: 2.8725 - acc: 0.3654 - val_loss: 2.8655 - val_acc: 0.3556\n",
            "Epoch 51/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 2.8576 - acc: 0.3654 - val_loss: 2.8503 - val_acc: 0.3525\n",
            "Epoch 52/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 2.8420 - acc: 0.3613 - val_loss: 2.8344 - val_acc: 0.3515\n",
            "Epoch 53/300\n",
            "4620/4620 [==============================] - 1s 204us/step - loss: 2.8257 - acc: 0.3623 - val_loss: 2.8178 - val_acc: 0.3510\n",
            "Epoch 54/300\n",
            " 288/4620 [>.............................] - ETA: 0s - loss: 2.8020 - acc: 0.3472"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 203us/step - loss: 2.8086 - acc: 0.3617 - val_loss: 2.8005 - val_acc: 0.3475\n",
            "Epoch 55/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 2.7909 - acc: 0.3613 - val_loss: 2.7825 - val_acc: 0.3460\n",
            "Epoch 56/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 2.7724 - acc: 0.3602 - val_loss: 2.7638 - val_acc: 0.3449\n",
            "Epoch 57/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 2.7533 - acc: 0.3587 - val_loss: 2.7445 - val_acc: 0.3419\n",
            "Epoch 58/300\n",
            "4620/4620 [==============================] - 1s 197us/step - loss: 2.7335 - acc: 0.3580 - val_loss: 2.7245 - val_acc: 0.3424\n",
            "Epoch 59/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 2.7131 - acc: 0.3582 - val_loss: 2.7039 - val_acc: 0.3409\n",
            "Epoch 60/300\n",
            "4620/4620 [==============================] - 1s 195us/step - loss: 2.6921 - acc: 0.3571 - val_loss: 2.6828 - val_acc: 0.3409\n",
            "Epoch 61/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 2.6706 - acc: 0.3545 - val_loss: 2.6611 - val_acc: 0.3399\n",
            "Epoch 62/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 2.6485 - acc: 0.3569 - val_loss: 2.6389 - val_acc: 0.3404\n",
            "Epoch 63/300\n",
            " 992/4620 [=====>........................] - ETA: 0s - loss: 2.6297 - acc: 0.3488"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 198us/step - loss: 2.6258 - acc: 0.3569 - val_loss: 2.6162 - val_acc: 0.3414\n",
            "Epoch 64/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 2.6027 - acc: 0.3574 - val_loss: 2.5929 - val_acc: 0.3414\n",
            "Epoch 65/300\n",
            "4620/4620 [==============================] - 1s 197us/step - loss: 2.5791 - acc: 0.3600 - val_loss: 2.5693 - val_acc: 0.3409\n",
            "Epoch 66/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 2.5551 - acc: 0.3630 - val_loss: 2.5453 - val_acc: 0.3424\n",
            "Epoch 67/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 2.5308 - acc: 0.3654 - val_loss: 2.5210 - val_acc: 0.3465\n",
            "Epoch 68/300\n",
            "4620/4620 [==============================] - 1s 204us/step - loss: 2.5062 - acc: 0.3690 - val_loss: 2.4963 - val_acc: 0.3485\n",
            "Epoch 69/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 2.4812 - acc: 0.3688 - val_loss: 2.4712 - val_acc: 0.3535\n",
            "Epoch 70/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 2.4560 - acc: 0.3742 - val_loss: 2.4459 - val_acc: 0.3576\n",
            "Epoch 71/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 2.4305 - acc: 0.3805 - val_loss: 2.4204 - val_acc: 0.3626\n",
            "Epoch 72/300\n",
            " 992/4620 [=====>........................] - ETA: 0s - loss: 2.3993 - acc: 0.3780"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 201us/step - loss: 2.4049 - acc: 0.3857 - val_loss: 2.3946 - val_acc: 0.3742\n",
            "Epoch 73/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 2.3790 - acc: 0.3937 - val_loss: 2.3686 - val_acc: 0.3818\n",
            "Epoch 74/300\n",
            "4620/4620 [==============================] - 1s 204us/step - loss: 2.3530 - acc: 0.4009 - val_loss: 2.3425 - val_acc: 0.3879\n",
            "Epoch 75/300\n",
            "4620/4620 [==============================] - 1s 197us/step - loss: 2.3269 - acc: 0.4097 - val_loss: 2.3163 - val_acc: 0.3970\n",
            "Epoch 76/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 2.3008 - acc: 0.4158 - val_loss: 2.2900 - val_acc: 0.4045\n",
            "Epoch 77/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 2.2746 - acc: 0.4221 - val_loss: 2.2637 - val_acc: 0.4081\n",
            "Epoch 78/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 2.2485 - acc: 0.4286 - val_loss: 2.2374 - val_acc: 0.4141\n",
            "Epoch 79/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 2.2224 - acc: 0.4329 - val_loss: 2.2111 - val_acc: 0.4182\n",
            "Epoch 80/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 2.1962 - acc: 0.4390 - val_loss: 2.1846 - val_acc: 0.4232\n",
            "Epoch 81/300\n",
            " 992/4620 [=====>........................] - ETA: 0s - loss: 2.1620 - acc: 0.4325"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 197us/step - loss: 2.1700 - acc: 0.4416 - val_loss: 2.1582 - val_acc: 0.4313\n",
            "Epoch 82/300\n",
            "4620/4620 [==============================] - 1s 197us/step - loss: 2.1438 - acc: 0.4448 - val_loss: 2.1319 - val_acc: 0.4328\n",
            "Epoch 83/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 2.1178 - acc: 0.4537 - val_loss: 2.1057 - val_acc: 0.4434\n",
            "Epoch 84/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 2.0919 - acc: 0.4595 - val_loss: 2.0796 - val_acc: 0.4515\n",
            "Epoch 85/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 2.0662 - acc: 0.4643 - val_loss: 2.0536 - val_acc: 0.4556\n",
            "Epoch 86/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 2.0407 - acc: 0.4747 - val_loss: 2.0278 - val_acc: 0.4601\n",
            "Epoch 87/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 2.0153 - acc: 0.4835 - val_loss: 2.0022 - val_acc: 0.4773\n",
            "Epoch 88/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 1.9901 - acc: 0.4898 - val_loss: 1.9768 - val_acc: 0.4848\n",
            "Epoch 89/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 1.9652 - acc: 0.4939 - val_loss: 1.9516 - val_acc: 0.4924\n",
            "Epoch 90/300\n",
            " 992/4620 [=====>........................] - ETA: 0s - loss: 2.0200 - acc: 0.4708"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 196us/step - loss: 1.9404 - acc: 0.4987 - val_loss: 1.9264 - val_acc: 0.4995\n",
            "Epoch 91/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 1.9158 - acc: 0.5106 - val_loss: 1.9015 - val_acc: 0.5061\n",
            "Epoch 92/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 1.8914 - acc: 0.5147 - val_loss: 1.8768 - val_acc: 0.5253\n",
            "Epoch 93/300\n",
            "4620/4620 [==============================] - 1s 195us/step - loss: 1.8672 - acc: 0.5310 - val_loss: 1.8523 - val_acc: 0.5298\n",
            "Epoch 94/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 1.8432 - acc: 0.5392 - val_loss: 1.8280 - val_acc: 0.5348\n",
            "Epoch 95/300\n",
            "4620/4620 [==============================] - 1s 205us/step - loss: 1.8195 - acc: 0.5374 - val_loss: 1.8040 - val_acc: 0.5404\n",
            "Epoch 96/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 1.7962 - acc: 0.5407 - val_loss: 1.7804 - val_acc: 0.5429\n",
            "Epoch 97/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 1.7731 - acc: 0.5439 - val_loss: 1.7571 - val_acc: 0.5439\n",
            "Epoch 98/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 1.7504 - acc: 0.5498 - val_loss: 1.7341 - val_acc: 0.5470\n",
            "Epoch 99/300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 200us/step - loss: 1.7280 - acc: 0.5511 - val_loss: 1.7115 - val_acc: 0.5551\n",
            "Epoch 100/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 1.7061 - acc: 0.5517 - val_loss: 1.6894 - val_acc: 0.5586\n",
            "Epoch 101/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 1.6845 - acc: 0.5535 - val_loss: 1.6676 - val_acc: 0.5631\n",
            "Epoch 102/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 1.6634 - acc: 0.5563 - val_loss: 1.6462 - val_acc: 0.5677\n",
            "Epoch 103/300\n",
            "4620/4620 [==============================] - 1s 206us/step - loss: 1.6426 - acc: 0.5593 - val_loss: 1.6253 - val_acc: 0.5667\n",
            "Epoch 104/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 1.6223 - acc: 0.5623 - val_loss: 1.6049 - val_acc: 0.5702\n",
            "Epoch 105/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 1.6026 - acc: 0.5660 - val_loss: 1.5850 - val_acc: 0.5742\n",
            "Epoch 106/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 1.5833 - acc: 0.5690 - val_loss: 1.5656 - val_acc: 0.5783\n",
            "Epoch 107/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 1.5645 - acc: 0.5751 - val_loss: 1.5464 - val_acc: 0.5818\n",
            "Epoch 108/300\n",
            " 320/4620 [=>............................] - ETA: 0s - loss: 1.5542 - acc: 0.5813"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 202us/step - loss: 1.5461 - acc: 0.5801 - val_loss: 1.5280 - val_acc: 0.5828\n",
            "Epoch 109/300\n",
            "4620/4620 [==============================] - 1s 197us/step - loss: 1.5283 - acc: 0.5792 - val_loss: 1.5099 - val_acc: 0.5874\n",
            "Epoch 110/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 1.5108 - acc: 0.5840 - val_loss: 1.4922 - val_acc: 0.5924\n",
            "Epoch 111/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 1.4938 - acc: 0.5896 - val_loss: 1.4753 - val_acc: 0.5909\n",
            "Epoch 112/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 1.4772 - acc: 0.5922 - val_loss: 1.4585 - val_acc: 0.5934\n",
            "Epoch 113/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 1.4612 - acc: 0.5952 - val_loss: 1.4424 - val_acc: 0.5960\n",
            "Epoch 114/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 1.4454 - acc: 0.5968 - val_loss: 1.4265 - val_acc: 0.6000\n",
            "Epoch 115/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 1.4300 - acc: 0.6004 - val_loss: 1.4111 - val_acc: 0.6025\n",
            "Epoch 116/300\n",
            "4620/4620 [==============================] - 1s 197us/step - loss: 1.4149 - acc: 0.6032 - val_loss: 1.3961 - val_acc: 0.6015\n",
            "Epoch 117/300\n",
            " 640/4620 [===>..........................] - ETA: 0s - loss: 1.4094 - acc: 0.6078"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 199us/step - loss: 1.4004 - acc: 0.6078 - val_loss: 1.3815 - val_acc: 0.6035\n",
            "Epoch 118/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 1.3861 - acc: 0.6061 - val_loss: 1.3676 - val_acc: 0.6076\n",
            "Epoch 119/300\n",
            "4620/4620 [==============================] - 1s 204us/step - loss: 1.3723 - acc: 0.6117 - val_loss: 1.3542 - val_acc: 0.6121\n",
            "Epoch 120/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 1.3588 - acc: 0.6130 - val_loss: 1.3405 - val_acc: 0.6177\n",
            "Epoch 121/300\n",
            "4620/4620 [==============================] - 1s 207us/step - loss: 1.3457 - acc: 0.6132 - val_loss: 1.3275 - val_acc: 0.6222\n",
            "Epoch 122/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 1.3329 - acc: 0.6210 - val_loss: 1.3147 - val_acc: 0.6212\n",
            "Epoch 123/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 1.3205 - acc: 0.6212 - val_loss: 1.3020 - val_acc: 0.6247\n",
            "Epoch 124/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 1.3083 - acc: 0.6251 - val_loss: 1.2897 - val_acc: 0.6258\n",
            "Epoch 125/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 1.2965 - acc: 0.6277 - val_loss: 1.2776 - val_acc: 0.6303\n",
            "Epoch 126/300\n",
            " 672/4620 [===>..........................] - ETA: 0s - loss: 1.2648 - acc: 0.6414"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 199us/step - loss: 1.2850 - acc: 0.6301 - val_loss: 1.2659 - val_acc: 0.6348\n",
            "Epoch 127/300\n",
            "4620/4620 [==============================] - 1s 195us/step - loss: 1.2737 - acc: 0.6303 - val_loss: 1.2551 - val_acc: 0.6414\n",
            "Epoch 128/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 1.2627 - acc: 0.6364 - val_loss: 1.2437 - val_acc: 0.6434\n",
            "Epoch 129/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 1.2521 - acc: 0.6379 - val_loss: 1.2329 - val_acc: 0.6500\n",
            "Epoch 130/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 1.2412 - acc: 0.6446 - val_loss: 1.2217 - val_acc: 0.6485\n",
            "Epoch 131/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 1.2303 - acc: 0.6474 - val_loss: 1.2112 - val_acc: 0.6535\n",
            "Epoch 132/300\n",
            "4620/4620 [==============================] - 1s 204us/step - loss: 1.2197 - acc: 0.6463 - val_loss: 1.2007 - val_acc: 0.6616\n",
            "Epoch 133/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 1.2093 - acc: 0.6545 - val_loss: 1.1904 - val_acc: 0.6682\n",
            "Epoch 134/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 1.1993 - acc: 0.6571 - val_loss: 1.1802 - val_acc: 0.6646\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 135/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 1.1893 - acc: 0.6556 - val_loss: 1.1705 - val_acc: 0.6682\n",
            "Epoch 136/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 1.1796 - acc: 0.6558 - val_loss: 1.1613 - val_acc: 0.6682\n",
            "Epoch 137/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 1.1702 - acc: 0.6589 - val_loss: 1.1525 - val_acc: 0.6737\n",
            "Epoch 138/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 1.1609 - acc: 0.6662 - val_loss: 1.1434 - val_acc: 0.6727\n",
            "Epoch 139/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 1.1520 - acc: 0.6688 - val_loss: 1.1343 - val_acc: 0.6793\n",
            "Epoch 140/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 1.1431 - acc: 0.6710 - val_loss: 1.1258 - val_acc: 0.6783\n",
            "Epoch 141/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 1.1343 - acc: 0.6695 - val_loss: 1.1166 - val_acc: 0.6793\n",
            "Epoch 142/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 1.1258 - acc: 0.6755 - val_loss: 1.1086 - val_acc: 0.6843\n",
            "Epoch 143/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 1.1175 - acc: 0.6786 - val_loss: 1.1008 - val_acc: 0.6843\n",
            "Epoch 144/300\n",
            "  32/4620 [..............................] - ETA: 1s - loss: 1.0391 - acc: 0.8125"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 198us/step - loss: 1.1093 - acc: 0.6797 - val_loss: 1.0926 - val_acc: 0.6854\n",
            "Epoch 145/300\n",
            "4620/4620 [==============================] - 1s 195us/step - loss: 1.1012 - acc: 0.6788 - val_loss: 1.0850 - val_acc: 0.6889\n",
            "Epoch 146/300\n",
            "4620/4620 [==============================] - 1s 215us/step - loss: 1.0932 - acc: 0.6857 - val_loss: 1.0777 - val_acc: 0.6904\n",
            "Epoch 147/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 1.0855 - acc: 0.6846 - val_loss: 1.0695 - val_acc: 0.6919\n",
            "Epoch 148/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 1.0779 - acc: 0.6859 - val_loss: 1.0619 - val_acc: 0.6899\n",
            "Epoch 149/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 1.0704 - acc: 0.6892 - val_loss: 1.0547 - val_acc: 0.6914\n",
            "Epoch 150/300\n",
            "4620/4620 [==============================] - 1s 197us/step - loss: 1.0631 - acc: 0.6924 - val_loss: 1.0480 - val_acc: 0.6949\n",
            "Epoch 151/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 1.0557 - acc: 0.6935 - val_loss: 1.0414 - val_acc: 0.7005\n",
            "Epoch 152/300\n",
            "4620/4620 [==============================] - 1s 194us/step - loss: 1.0488 - acc: 0.6944 - val_loss: 1.0340 - val_acc: 0.7015\n",
            "Epoch 153/300\n",
            " 288/4620 [>.............................] - ETA: 0s - loss: 1.1193 - acc: 0.6632"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 201us/step - loss: 1.0417 - acc: 0.6981 - val_loss: 1.0269 - val_acc: 0.7000\n",
            "Epoch 154/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 1.0348 - acc: 0.6976 - val_loss: 1.0212 - val_acc: 0.7025\n",
            "Epoch 155/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 1.0282 - acc: 0.7017 - val_loss: 1.0141 - val_acc: 0.7045\n",
            "Epoch 156/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 1.0216 - acc: 0.7054 - val_loss: 1.0079 - val_acc: 0.7025\n",
            "Epoch 157/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 1.0150 - acc: 0.7052 - val_loss: 1.0015 - val_acc: 0.7076\n",
            "Epoch 158/300\n",
            "4620/4620 [==============================] - 1s 193us/step - loss: 1.0087 - acc: 0.7052 - val_loss: 0.9954 - val_acc: 0.7121\n",
            "Epoch 159/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 1.0024 - acc: 0.7065 - val_loss: 0.9897 - val_acc: 0.7101\n",
            "Epoch 160/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.9962 - acc: 0.7121 - val_loss: 0.9834 - val_acc: 0.7101\n",
            "Epoch 161/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.9902 - acc: 0.7097 - val_loss: 0.9778 - val_acc: 0.7157\n",
            "Epoch 162/300\n",
            " 352/4620 [=>............................] - ETA: 0s - loss: 1.0020 - acc: 0.7415"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 194us/step - loss: 0.9843 - acc: 0.7147 - val_loss: 0.9722 - val_acc: 0.7192\n",
            "Epoch 163/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.9782 - acc: 0.7165 - val_loss: 0.9668 - val_acc: 0.7222\n",
            "Epoch 164/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.9724 - acc: 0.7152 - val_loss: 0.9614 - val_acc: 0.7258\n",
            "Epoch 165/300\n",
            "4620/4620 [==============================] - 1s 204us/step - loss: 0.9669 - acc: 0.7214 - val_loss: 0.9555 - val_acc: 0.7288\n",
            "Epoch 166/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.9611 - acc: 0.7210 - val_loss: 0.9510 - val_acc: 0.7343\n",
            "Epoch 167/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 0.9557 - acc: 0.7247 - val_loss: 0.9454 - val_acc: 0.7298\n",
            "Epoch 168/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 0.9504 - acc: 0.7279 - val_loss: 0.9401 - val_acc: 0.7247\n",
            "Epoch 169/300\n",
            "4620/4620 [==============================] - 1s 197us/step - loss: 0.9450 - acc: 0.7242 - val_loss: 0.9359 - val_acc: 0.7283\n",
            "Epoch 170/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 0.9397 - acc: 0.7262 - val_loss: 0.9297 - val_acc: 0.7308\n",
            "Epoch 171/300\n",
            " 992/4620 [=====>........................] - ETA: 0s - loss: 0.8867 - acc: 0.7530"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 199us/step - loss: 0.9346 - acc: 0.7279 - val_loss: 0.9251 - val_acc: 0.7308\n",
            "Epoch 172/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.9296 - acc: 0.7297 - val_loss: 0.9198 - val_acc: 0.7338\n",
            "Epoch 173/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.9245 - acc: 0.7312 - val_loss: 0.9157 - val_acc: 0.7333\n",
            "Epoch 174/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.9197 - acc: 0.7320 - val_loss: 0.9110 - val_acc: 0.7369\n",
            "Epoch 175/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.9148 - acc: 0.7323 - val_loss: 0.9070 - val_acc: 0.7389\n",
            "Epoch 176/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.9102 - acc: 0.7351 - val_loss: 0.9023 - val_acc: 0.7399\n",
            "Epoch 177/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.9053 - acc: 0.7383 - val_loss: 0.8981 - val_acc: 0.7354\n",
            "Epoch 178/300\n",
            "4620/4620 [==============================] - 1s 197us/step - loss: 0.9006 - acc: 0.7368 - val_loss: 0.8935 - val_acc: 0.7465\n",
            "Epoch 179/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.8960 - acc: 0.7442 - val_loss: 0.8885 - val_acc: 0.7429\n",
            "Epoch 180/300\n",
            " 672/4620 [===>..........................] - ETA: 0s - loss: 0.8666 - acc: 0.7366"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 204us/step - loss: 0.8917 - acc: 0.7398 - val_loss: 0.8844 - val_acc: 0.7439\n",
            "Epoch 181/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.8871 - acc: 0.7409 - val_loss: 0.8810 - val_acc: 0.7434\n",
            "Epoch 182/300\n",
            "4620/4620 [==============================] - 1s 194us/step - loss: 0.8827 - acc: 0.7431 - val_loss: 0.8765 - val_acc: 0.7455\n",
            "Epoch 183/300\n",
            "4620/4620 [==============================] - 1s 195us/step - loss: 0.8785 - acc: 0.7429 - val_loss: 0.8726 - val_acc: 0.7505\n",
            "Epoch 184/300\n",
            "4620/4620 [==============================] - 1s 194us/step - loss: 0.8742 - acc: 0.7442 - val_loss: 0.8684 - val_acc: 0.7530\n",
            "Epoch 185/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 0.8701 - acc: 0.7455 - val_loss: 0.8641 - val_acc: 0.7510\n",
            "Epoch 186/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.8660 - acc: 0.7485 - val_loss: 0.8611 - val_acc: 0.7510\n",
            "Epoch 187/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.8618 - acc: 0.7494 - val_loss: 0.8571 - val_acc: 0.7561\n",
            "Epoch 188/300\n",
            "4620/4620 [==============================] - 1s 195us/step - loss: 0.8580 - acc: 0.7494 - val_loss: 0.8540 - val_acc: 0.7535\n",
            "Epoch 189/300\n",
            " 928/4620 [=====>........................] - ETA: 0s - loss: 0.8701 - acc: 0.7403"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 196us/step - loss: 0.8540 - acc: 0.7511 - val_loss: 0.8493 - val_acc: 0.7596\n",
            "Epoch 190/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.8500 - acc: 0.7509 - val_loss: 0.8464 - val_acc: 0.7571\n",
            "Epoch 191/300\n",
            "4620/4620 [==============================] - 1s 197us/step - loss: 0.8464 - acc: 0.7545 - val_loss: 0.8425 - val_acc: 0.7571\n",
            "Epoch 192/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.8424 - acc: 0.7539 - val_loss: 0.8392 - val_acc: 0.7626\n",
            "Epoch 193/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.8388 - acc: 0.7532 - val_loss: 0.8363 - val_acc: 0.7606\n",
            "Epoch 194/300\n",
            "4620/4620 [==============================] - 1s 206us/step - loss: 0.8350 - acc: 0.7563 - val_loss: 0.8325 - val_acc: 0.7606\n",
            "Epoch 195/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.8315 - acc: 0.7567 - val_loss: 0.8294 - val_acc: 0.7606\n",
            "Epoch 196/300\n",
            "4620/4620 [==============================] - 1s 204us/step - loss: 0.8279 - acc: 0.7548 - val_loss: 0.8263 - val_acc: 0.7641\n",
            "Epoch 197/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.8244 - acc: 0.7582 - val_loss: 0.8226 - val_acc: 0.7611\n",
            "Epoch 198/300\n",
            "  32/4620 [..............................] - ETA: 1s - loss: 0.9337 - acc: 0.7812"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 195us/step - loss: 0.8208 - acc: 0.7589 - val_loss: 0.8195 - val_acc: 0.7611\n",
            "Epoch 199/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 0.8174 - acc: 0.7613 - val_loss: 0.8155 - val_acc: 0.7657\n",
            "Epoch 200/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 0.8140 - acc: 0.7593 - val_loss: 0.8122 - val_acc: 0.7652\n",
            "Epoch 201/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.8106 - acc: 0.7619 - val_loss: 0.8098 - val_acc: 0.7641\n",
            "Epoch 202/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 0.8073 - acc: 0.7619 - val_loss: 0.8066 - val_acc: 0.7641\n",
            "Epoch 203/300\n",
            "4620/4620 [==============================] - 1s 205us/step - loss: 0.8041 - acc: 0.7647 - val_loss: 0.8035 - val_acc: 0.7667\n",
            "Epoch 204/300\n",
            "4620/4620 [==============================] - 1s 206us/step - loss: 0.8008 - acc: 0.7606 - val_loss: 0.7999 - val_acc: 0.7677\n",
            "Epoch 205/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.7977 - acc: 0.7647 - val_loss: 0.7971 - val_acc: 0.7667\n",
            "Epoch 206/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.7943 - acc: 0.7658 - val_loss: 0.7948 - val_acc: 0.7712\n",
            "Epoch 207/300\n",
            "  32/4620 [..............................] - ETA: 1s - loss: 0.9932 - acc: 0.6250"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.7915 - acc: 0.7660 - val_loss: 0.7916 - val_acc: 0.7722\n",
            "Epoch 208/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.7882 - acc: 0.7660 - val_loss: 0.7897 - val_acc: 0.7707\n",
            "Epoch 209/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.7853 - acc: 0.7671 - val_loss: 0.7870 - val_acc: 0.7697\n",
            "Epoch 210/300\n",
            "4620/4620 [==============================] - 1s 204us/step - loss: 0.7821 - acc: 0.7686 - val_loss: 0.7840 - val_acc: 0.7712\n",
            "Epoch 211/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.7790 - acc: 0.7686 - val_loss: 0.7812 - val_acc: 0.7712\n",
            "Epoch 212/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.7761 - acc: 0.7712 - val_loss: 0.7780 - val_acc: 0.7712\n",
            "Epoch 213/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.7734 - acc: 0.7695 - val_loss: 0.7756 - val_acc: 0.7727\n",
            "Epoch 214/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.7702 - acc: 0.7714 - val_loss: 0.7728 - val_acc: 0.7763\n",
            "Epoch 215/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.7674 - acc: 0.7732 - val_loss: 0.7697 - val_acc: 0.7753\n",
            "Epoch 216/300\n",
            " 672/4620 [===>..........................] - ETA: 0s - loss: 0.7394 - acc: 0.7812"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.7646 - acc: 0.7727 - val_loss: 0.7678 - val_acc: 0.7768\n",
            "Epoch 217/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 0.7618 - acc: 0.7734 - val_loss: 0.7644 - val_acc: 0.7788\n",
            "Epoch 218/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.7591 - acc: 0.7729 - val_loss: 0.7617 - val_acc: 0.7747\n",
            "Epoch 219/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.7563 - acc: 0.7755 - val_loss: 0.7597 - val_acc: 0.7758\n",
            "Epoch 220/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.7535 - acc: 0.7764 - val_loss: 0.7585 - val_acc: 0.7753\n",
            "Epoch 221/300\n",
            "4620/4620 [==============================] - 1s 197us/step - loss: 0.7507 - acc: 0.7786 - val_loss: 0.7547 - val_acc: 0.7828\n",
            "Epoch 222/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.7485 - acc: 0.7784 - val_loss: 0.7536 - val_acc: 0.7803\n",
            "Epoch 223/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.7457 - acc: 0.7753 - val_loss: 0.7501 - val_acc: 0.7808\n",
            "Epoch 224/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 0.7434 - acc: 0.7779 - val_loss: 0.7481 - val_acc: 0.7798\n",
            "Epoch 225/300\n",
            " 992/4620 [=====>........................] - ETA: 0s - loss: 0.7340 - acc: 0.7873"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.7406 - acc: 0.7805 - val_loss: 0.7454 - val_acc: 0.7823\n",
            "Epoch 226/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.7381 - acc: 0.7814 - val_loss: 0.7439 - val_acc: 0.7828\n",
            "Epoch 227/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.7357 - acc: 0.7805 - val_loss: 0.7402 - val_acc: 0.7854\n",
            "Epoch 228/300\n",
            "4620/4620 [==============================] - 1s 204us/step - loss: 0.7331 - acc: 0.7829 - val_loss: 0.7381 - val_acc: 0.7854\n",
            "Epoch 229/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.7306 - acc: 0.7818 - val_loss: 0.7360 - val_acc: 0.7833\n",
            "Epoch 230/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.7281 - acc: 0.7842 - val_loss: 0.7346 - val_acc: 0.7833\n",
            "Epoch 231/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.7259 - acc: 0.7851 - val_loss: 0.7318 - val_acc: 0.7833\n",
            "Epoch 232/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.7236 - acc: 0.7838 - val_loss: 0.7284 - val_acc: 0.7889\n",
            "Epoch 233/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.7212 - acc: 0.7861 - val_loss: 0.7268 - val_acc: 0.7869\n",
            "Epoch 234/300\n",
            " 608/4620 [==>...........................] - ETA: 0s - loss: 0.6720 - acc: 0.8125"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.7185 - acc: 0.7861 - val_loss: 0.7263 - val_acc: 0.7864\n",
            "Epoch 235/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.7166 - acc: 0.7885 - val_loss: 0.7240 - val_acc: 0.7848\n",
            "Epoch 236/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.7141 - acc: 0.7846 - val_loss: 0.7212 - val_acc: 0.7879\n",
            "Epoch 237/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.7119 - acc: 0.7853 - val_loss: 0.7190 - val_acc: 0.7904\n",
            "Epoch 238/300\n",
            "4620/4620 [==============================] - 1s 205us/step - loss: 0.7099 - acc: 0.7872 - val_loss: 0.7166 - val_acc: 0.7869\n",
            "Epoch 239/300\n",
            "4620/4620 [==============================] - 1s 204us/step - loss: 0.7074 - acc: 0.7900 - val_loss: 0.7158 - val_acc: 0.7894\n",
            "Epoch 240/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.7053 - acc: 0.7887 - val_loss: 0.7131 - val_acc: 0.7874\n",
            "Epoch 241/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 0.7030 - acc: 0.7877 - val_loss: 0.7105 - val_acc: 0.7889\n",
            "Epoch 242/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.7010 - acc: 0.7887 - val_loss: 0.7081 - val_acc: 0.7909\n",
            "Epoch 243/300\n",
            "  32/4620 [..............................] - ETA: 1s - loss: 0.5712 - acc: 0.7188"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.6986 - acc: 0.7911 - val_loss: 0.7080 - val_acc: 0.7899\n",
            "Epoch 244/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.6965 - acc: 0.7926 - val_loss: 0.7046 - val_acc: 0.7914\n",
            "Epoch 245/300\n",
            "4620/4620 [==============================] - 1s 203us/step - loss: 0.6944 - acc: 0.7892 - val_loss: 0.7036 - val_acc: 0.7899\n",
            "Epoch 246/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.6923 - acc: 0.7907 - val_loss: 0.7014 - val_acc: 0.7939\n",
            "Epoch 247/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 0.6902 - acc: 0.7944 - val_loss: 0.7008 - val_acc: 0.7904\n",
            "Epoch 248/300\n",
            "4620/4620 [==============================] - 1s 205us/step - loss: 0.6882 - acc: 0.7939 - val_loss: 0.6970 - val_acc: 0.7929\n",
            "Epoch 249/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.6863 - acc: 0.7922 - val_loss: 0.6951 - val_acc: 0.7924\n",
            "Epoch 250/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.6843 - acc: 0.7935 - val_loss: 0.6925 - val_acc: 0.7924\n",
            "Epoch 251/300\n",
            "4620/4620 [==============================] - 1s 204us/step - loss: 0.6821 - acc: 0.7944 - val_loss: 0.6913 - val_acc: 0.7929\n",
            "Epoch 252/300\n",
            " 352/4620 [=>............................] - ETA: 0s - loss: 0.7157 - acc: 0.7983"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.6803 - acc: 0.7948 - val_loss: 0.6898 - val_acc: 0.7934\n",
            "Epoch 253/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 0.6783 - acc: 0.7957 - val_loss: 0.6877 - val_acc: 0.7944\n",
            "Epoch 254/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 0.6760 - acc: 0.7946 - val_loss: 0.6859 - val_acc: 0.7934\n",
            "Epoch 255/300\n",
            "4620/4620 [==============================] - 1s 205us/step - loss: 0.6744 - acc: 0.7968 - val_loss: 0.6843 - val_acc: 0.7955\n",
            "Epoch 256/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.6723 - acc: 0.7981 - val_loss: 0.6822 - val_acc: 0.7939\n",
            "Epoch 257/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 0.6703 - acc: 0.7944 - val_loss: 0.6807 - val_acc: 0.7929\n",
            "Epoch 258/300\n",
            "4620/4620 [==============================] - 1s 197us/step - loss: 0.6685 - acc: 0.7976 - val_loss: 0.6783 - val_acc: 0.7965\n",
            "Epoch 259/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 0.6666 - acc: 0.7987 - val_loss: 0.6778 - val_acc: 0.7919\n",
            "Epoch 260/300\n",
            "4620/4620 [==============================] - 1s 194us/step - loss: 0.6648 - acc: 0.7974 - val_loss: 0.6755 - val_acc: 0.7960\n",
            "Epoch 261/300\n",
            " 672/4620 [===>..........................] - ETA: 0s - loss: 0.6235 - acc: 0.8110"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 193us/step - loss: 0.6628 - acc: 0.7968 - val_loss: 0.6744 - val_acc: 0.7949\n",
            "Epoch 262/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.6610 - acc: 0.7994 - val_loss: 0.6723 - val_acc: 0.7949\n",
            "Epoch 263/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.6587 - acc: 0.7991 - val_loss: 0.6713 - val_acc: 0.7955\n",
            "Epoch 264/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.6574 - acc: 0.8006 - val_loss: 0.6693 - val_acc: 0.7944\n",
            "Epoch 265/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.6554 - acc: 0.7981 - val_loss: 0.6655 - val_acc: 0.7990\n",
            "Epoch 266/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.6533 - acc: 0.8017 - val_loss: 0.6664 - val_acc: 0.7975\n",
            "Epoch 267/300\n",
            "4620/4620 [==============================] - 1s 204us/step - loss: 0.6518 - acc: 0.7998 - val_loss: 0.6638 - val_acc: 0.7985\n",
            "Epoch 268/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.6500 - acc: 0.8006 - val_loss: 0.6622 - val_acc: 0.7975\n",
            "Epoch 269/300\n",
            "4620/4620 [==============================] - 1s 202us/step - loss: 0.6482 - acc: 0.8015 - val_loss: 0.6605 - val_acc: 0.7985\n",
            "Epoch 270/300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.6463 - acc: 0.8037 - val_loss: 0.6582 - val_acc: 0.7990\n",
            "Epoch 271/300\n",
            "4620/4620 [==============================] - 1s 197us/step - loss: 0.6446 - acc: 0.8017 - val_loss: 0.6581 - val_acc: 0.7980\n",
            "Epoch 272/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.6428 - acc: 0.8011 - val_loss: 0.6569 - val_acc: 0.8015\n",
            "Epoch 273/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.6411 - acc: 0.8030 - val_loss: 0.6538 - val_acc: 0.7995\n",
            "Epoch 274/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.6395 - acc: 0.8024 - val_loss: 0.6510 - val_acc: 0.8010\n",
            "Epoch 275/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.6374 - acc: 0.8048 - val_loss: 0.6508 - val_acc: 0.8020\n",
            "Epoch 276/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.6359 - acc: 0.8069 - val_loss: 0.6509 - val_acc: 0.8005\n",
            "Epoch 277/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.6345 - acc: 0.8054 - val_loss: 0.6475 - val_acc: 0.8000\n",
            "Epoch 278/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 0.6325 - acc: 0.8061 - val_loss: 0.6460 - val_acc: 0.7995\n",
            "Epoch 279/300\n",
            "1024/4620 [=====>........................] - ETA: 0s - loss: 0.6365 - acc: 0.8154"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 197us/step - loss: 0.6308 - acc: 0.8076 - val_loss: 0.6433 - val_acc: 0.8030\n",
            "Epoch 280/300\n",
            "4620/4620 [==============================] - 1s 197us/step - loss: 0.6290 - acc: 0.8076 - val_loss: 0.6420 - val_acc: 0.8025\n",
            "Epoch 281/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.6275 - acc: 0.8071 - val_loss: 0.6410 - val_acc: 0.8010\n",
            "Epoch 282/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.6257 - acc: 0.8089 - val_loss: 0.6407 - val_acc: 0.8040\n",
            "Epoch 283/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 0.6241 - acc: 0.8063 - val_loss: 0.6385 - val_acc: 0.8020\n",
            "Epoch 284/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 0.6224 - acc: 0.8110 - val_loss: 0.6364 - val_acc: 0.8025\n",
            "Epoch 285/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 0.6209 - acc: 0.8119 - val_loss: 0.6351 - val_acc: 0.8045\n",
            "Epoch 286/300\n",
            "4620/4620 [==============================] - 1s 193us/step - loss: 0.6193 - acc: 0.8093 - val_loss: 0.6339 - val_acc: 0.8025\n",
            "Epoch 287/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 0.6176 - acc: 0.8113 - val_loss: 0.6318 - val_acc: 0.8035\n",
            "Epoch 288/300\n",
            "1280/4620 [=======>......................] - ETA: 0s - loss: 0.6277 - acc: 0.8133"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 197us/step - loss: 0.6159 - acc: 0.8132 - val_loss: 0.6308 - val_acc: 0.8051\n",
            "Epoch 289/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.6144 - acc: 0.8117 - val_loss: 0.6299 - val_acc: 0.8035\n",
            "Epoch 290/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 0.6129 - acc: 0.8115 - val_loss: 0.6280 - val_acc: 0.8056\n",
            "Epoch 291/300\n",
            "4620/4620 [==============================] - 1s 201us/step - loss: 0.6109 - acc: 0.8115 - val_loss: 0.6267 - val_acc: 0.8045\n",
            "Epoch 292/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.6095 - acc: 0.8119 - val_loss: 0.6254 - val_acc: 0.8035\n",
            "Epoch 293/300\n",
            "4620/4620 [==============================] - 1s 200us/step - loss: 0.6079 - acc: 0.8123 - val_loss: 0.6221 - val_acc: 0.8081\n",
            "Epoch 294/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 0.6064 - acc: 0.8134 - val_loss: 0.6219 - val_acc: 0.8081\n",
            "Epoch 295/300\n",
            "4620/4620 [==============================] - 1s 195us/step - loss: 0.6048 - acc: 0.8141 - val_loss: 0.6208 - val_acc: 0.8106\n",
            "Epoch 296/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 0.6032 - acc: 0.8169 - val_loss: 0.6186 - val_acc: 0.8096\n",
            "Epoch 297/300\n",
            " 992/4620 [=====>........................] - ETA: 0s - loss: 0.5858 - acc: 0.8115"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 203us/step - loss: 0.6017 - acc: 0.8141 - val_loss: 0.6177 - val_acc: 0.8061\n",
            "Epoch 298/300\n",
            "4620/4620 [==============================] - 1s 196us/step - loss: 0.6000 - acc: 0.8158 - val_loss: 0.6154 - val_acc: 0.8091\n",
            "Epoch 299/300\n",
            "4620/4620 [==============================] - 1s 199us/step - loss: 0.5988 - acc: 0.8167 - val_loss: 0.6148 - val_acc: 0.8086\n",
            "Epoch 300/300\n",
            "4620/4620 [==============================] - 1s 198us/step - loss: 0.5969 - acc: 0.8162 - val_loss: 0.6138 - val_acc: 0.8086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uQAbEwFIMNVy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87ed2abe-2cc6-48e0-d7ba-1bdc226a6bde",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525440529691,
          "user_tz": 180,
          "elapsed": 655,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test_scaled, Y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1980/1980 [==============================] - 0s 70us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RGMaeGHpMV-j",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8e955a18-c7fb-403e-8927-7f10bf2d7cd2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525440535017,
          "user_tz": 180,
          "elapsed": 1677,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Cross entropy loss:\", score[0])\n",
        "print(\"Accuracy: \", score[1])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross entropy loss: 0.6137782636916999\n",
            "Accuracy:  0.8085858589470989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TDu1yGkaY9EN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Se ve como se logra un accuracy del $81\\%$, lo cual supera al $75\\%$ que se tenía como objetivo."
      ]
    },
    {
      "metadata": {
        "id": "z2awAGDdKL8H",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def plot(hist):\n",
        "  loss = hist['loss']\n",
        "  val_loss = hist['val_loss']\n",
        "  epochs = range(1, len(loss) + 1)\n",
        "  \n",
        "  fig = plt.figure(figsize=(16,5))\n",
        "  ax = fig.add_subplot(1, 2, 1)\n",
        "  ax.plot(epochs, loss, 'bo-', label = \"Training set\")\n",
        "  ax.plot(epochs, val_loss, 'go-', label = \"Test set\")\n",
        "  ax.set_title('Loss de CNN')\n",
        "  ax.set_xlabel('Epoch')\n",
        "  ax.set_ylabel('Loss')\n",
        "  #ax.set_ylim(0,2)\n",
        "  ax.legend(loc=\"upper right\", fancybox= True)\n",
        "\n",
        "  acc = hist['acc']\n",
        "  val_acc = hist['val_acc']\n",
        "  ax = fig.add_subplot(1, 2, 2)\n",
        "  ax.plot(epochs, np.subtract(1,acc), 'bo-', label = \"Training set\")\n",
        "  ax.plot(epochs, np.subtract(1,val_acc), 'go-', label = \"Test set\")\n",
        "  ax.set_title('Error de CNN')\n",
        "  ax.set_xlabel('Epoch')\n",
        "  ax.set_ylabel('Error')\n",
        "  #ax.set_ylim(0,.8)\n",
        "  ax.legend(loc=\"upper right\", fancybox= True)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zdN4TxDQMf3P",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "b8c55ab0-6d18-4230-a7b4-3413b6d7d9a0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525440547881,
          "user_tz": 180,
          "elapsed": 1105,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plot(model_fit.history)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA64AAAFMCAYAAADLFeHSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUwgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f45bcf2d898>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "iAKA9RC4ZBJK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finalmente, se presentan el error y función de pérdida del entrenamiento y prueba por epoch, donde se ve que tienen un comportamiento muy similar, por lo que se podría pensar que las características que la red extrajo del conjunto de entrenamiento, son justamente las que se encuentran en el conjunto prueba."
      ]
    },
    {
      "metadata": {
        "id": "e0ESbqf7ZF8s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ahora, probando con otro oprimizador como RMSprop, con la misma tasa de aprendizaje $0.001$ y un decay de $1e-3$"
      ]
    },
    {
      "metadata": {
        "id": "4nklEXTlWXiq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "51a4acd8-3dec-48bd-c495-bbc6e3a914be",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525440695059,
          "user_tz": 180,
          "elapsed": 684,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(200, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform'))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dense(400, kernel_initializer='uniform'))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dense(200))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dense(24, activation='softmax'))\n",
        "model2.summary()\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 200)               1800      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 400)               80400     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 200)               80200     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 24)                4824      \n",
            "=================================================================\n",
            "Total params: 167,224\n",
            "Trainable params: 167,224\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AvlEnexLTaz4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "rms = rmsprop(lr=0.001, decay=1e-3)\n",
        "model2.compile(optimizer=rms,loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HEFKgR94WAeh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 10254
        },
        "outputId": "e9e7a848-26a5-4d06-f348-af56b63ce9a2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525441082378,
          "user_tz": 180,
          "elapsed": 324989,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model_fit_rms = model2.fit(X_train_scaled, Y_train, epochs=300, verbose=1, validation_data=(X_test_scaled, Y_test), shuffle=True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4620 samples, validate on 1980 samples\n",
            "Epoch 1/300\n",
            "4620/4620 [==============================] - 1s 256us/step - loss: 1.3305 - acc: 0.5874 - val_loss: 0.8018 - val_acc: 0.7207\n",
            "Epoch 2/300\n",
            "4620/4620 [==============================] - 1s 220us/step - loss: 0.6808 - acc: 0.7690 - val_loss: 0.6445 - val_acc: 0.7833\n",
            "Epoch 3/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.5270 - acc: 0.8262 - val_loss: 0.5099 - val_acc: 0.8359\n",
            "Epoch 4/300\n",
            "4620/4620 [==============================] - 1s 239us/step - loss: 0.4197 - acc: 0.8649 - val_loss: 0.4303 - val_acc: 0.8505\n",
            "Epoch 5/300\n",
            "4620/4620 [==============================] - 1s 238us/step - loss: 0.3654 - acc: 0.8818 - val_loss: 0.4670 - val_acc: 0.8328\n",
            "Epoch 6/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.3194 - acc: 0.8987 - val_loss: 0.3606 - val_acc: 0.8828\n",
            "Epoch 7/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.2835 - acc: 0.9121 - val_loss: 0.3297 - val_acc: 0.8889\n",
            "Epoch 8/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.2632 - acc: 0.9167 - val_loss: 0.3124 - val_acc: 0.8975\n",
            "Epoch 9/300\n",
            " 288/4620 [>.............................] - ETA: 0s - loss: 0.3018 - acc: 0.9097"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 237us/step - loss: 0.2434 - acc: 0.9245 - val_loss: 0.2817 - val_acc: 0.9035\n",
            "Epoch 10/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.2230 - acc: 0.9299 - val_loss: 0.2897 - val_acc: 0.9045\n",
            "Epoch 11/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.2111 - acc: 0.9331 - val_loss: 0.2468 - val_acc: 0.9197\n",
            "Epoch 12/300\n",
            "4620/4620 [==============================] - 1s 239us/step - loss: 0.1993 - acc: 0.9359 - val_loss: 0.2561 - val_acc: 0.9081\n",
            "Epoch 13/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.1871 - acc: 0.9398 - val_loss: 0.2195 - val_acc: 0.9268\n",
            "Epoch 14/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.1790 - acc: 0.9465 - val_loss: 0.2353 - val_acc: 0.9207\n",
            "Epoch 15/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.1701 - acc: 0.9468 - val_loss: 0.2244 - val_acc: 0.9263\n",
            "Epoch 16/300\n",
            "4620/4620 [==============================] - 1s 226us/step - loss: 0.1608 - acc: 0.9506 - val_loss: 0.2133 - val_acc: 0.9318\n",
            "Epoch 17/300\n",
            "2432/4620 [==============>...............] - ETA: 0s - loss: 0.1593 - acc: 0.9552"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.1551 - acc: 0.9535 - val_loss: 0.2490 - val_acc: 0.9247\n",
            "Epoch 18/300\n",
            "4620/4620 [==============================] - 1s 231us/step - loss: 0.1484 - acc: 0.9561 - val_loss: 0.1982 - val_acc: 0.9343\n",
            "Epoch 19/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.1437 - acc: 0.9578 - val_loss: 0.1930 - val_acc: 0.9399\n",
            "Epoch 20/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.1367 - acc: 0.9602 - val_loss: 0.2072 - val_acc: 0.9343\n",
            "Epoch 21/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.1335 - acc: 0.9628 - val_loss: 0.1975 - val_acc: 0.9374\n",
            "Epoch 22/300\n",
            "4620/4620 [==============================] - 1s 227us/step - loss: 0.1293 - acc: 0.9636 - val_loss: 0.1788 - val_acc: 0.9429\n",
            "Epoch 23/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.1279 - acc: 0.9628 - val_loss: 0.1805 - val_acc: 0.9424\n",
            "Epoch 24/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.1241 - acc: 0.9645 - val_loss: 0.1914 - val_acc: 0.9364\n",
            "Epoch 25/300\n",
            "2784/4620 [=================>............] - ETA: 0s - loss: 0.1143 - acc: 0.9705"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.1171 - acc: 0.9690 - val_loss: 0.1687 - val_acc: 0.9490\n",
            "Epoch 26/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.1169 - acc: 0.9665 - val_loss: 0.1683 - val_acc: 0.9439\n",
            "Epoch 27/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.1144 - acc: 0.9690 - val_loss: 0.1650 - val_acc: 0.9455\n",
            "Epoch 28/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.1117 - acc: 0.9706 - val_loss: 0.1683 - val_acc: 0.9465\n",
            "Epoch 29/300\n",
            "4620/4620 [==============================] - 1s 237us/step - loss: 0.1091 - acc: 0.9710 - val_loss: 0.1653 - val_acc: 0.9449\n",
            "Epoch 30/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.1062 - acc: 0.9721 - val_loss: 0.1581 - val_acc: 0.9500\n",
            "Epoch 31/300\n",
            "4620/4620 [==============================] - 1s 229us/step - loss: 0.1017 - acc: 0.9729 - val_loss: 0.1809 - val_acc: 0.9409\n",
            "Epoch 32/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.1025 - acc: 0.9736 - val_loss: 0.1704 - val_acc: 0.9470\n",
            "Epoch 33/300\n",
            "2144/4620 [============>.................] - ETA: 0s - loss: 0.0941 - acc: 0.9743"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 227us/step - loss: 0.1005 - acc: 0.9745 - val_loss: 0.1662 - val_acc: 0.9495\n",
            "Epoch 34/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0963 - acc: 0.9766 - val_loss: 0.1642 - val_acc: 0.9460\n",
            "Epoch 35/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0954 - acc: 0.9784 - val_loss: 0.1546 - val_acc: 0.9520\n",
            "Epoch 36/300\n",
            "4620/4620 [==============================] - 1s 229us/step - loss: 0.0939 - acc: 0.9764 - val_loss: 0.1507 - val_acc: 0.9540\n",
            "Epoch 37/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0937 - acc: 0.9781 - val_loss: 0.1511 - val_acc: 0.9505\n",
            "Epoch 38/300\n",
            "4620/4620 [==============================] - 1s 231us/step - loss: 0.0919 - acc: 0.9777 - val_loss: 0.1517 - val_acc: 0.9480\n",
            "Epoch 39/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0889 - acc: 0.9799 - val_loss: 0.1518 - val_acc: 0.9515\n",
            "Epoch 40/300\n",
            "4620/4620 [==============================] - 1s 225us/step - loss: 0.0891 - acc: 0.9784 - val_loss: 0.1487 - val_acc: 0.9515\n",
            "Epoch 41/300\n",
            "2624/4620 [================>.............] - ETA: 0s - loss: 0.0811 - acc: 0.9806"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 228us/step - loss: 0.0865 - acc: 0.9794 - val_loss: 0.1539 - val_acc: 0.9475\n",
            "Epoch 42/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0861 - acc: 0.9812 - val_loss: 0.1525 - val_acc: 0.9500\n",
            "Epoch 43/300\n",
            "4620/4620 [==============================] - 1s 226us/step - loss: 0.0849 - acc: 0.9816 - val_loss: 0.1512 - val_acc: 0.9530\n",
            "Epoch 44/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0829 - acc: 0.9825 - val_loss: 0.1530 - val_acc: 0.9490\n",
            "Epoch 45/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0829 - acc: 0.9818 - val_loss: 0.1457 - val_acc: 0.9510\n",
            "Epoch 46/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0821 - acc: 0.9818 - val_loss: 0.1493 - val_acc: 0.9515\n",
            "Epoch 47/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0808 - acc: 0.9818 - val_loss: 0.1429 - val_acc: 0.9571\n",
            "Epoch 48/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0804 - acc: 0.9829 - val_loss: 0.1556 - val_acc: 0.9470\n",
            "Epoch 49/300\n",
            "2688/4620 [================>.............] - ETA: 0s - loss: 0.0752 - acc: 0.9814"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 228us/step - loss: 0.0785 - acc: 0.9827 - val_loss: 0.1564 - val_acc: 0.9465\n",
            "Epoch 50/300\n",
            "4620/4620 [==============================] - 1s 228us/step - loss: 0.0781 - acc: 0.9810 - val_loss: 0.1446 - val_acc: 0.9515\n",
            "Epoch 51/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0756 - acc: 0.9838 - val_loss: 0.1468 - val_acc: 0.9540\n",
            "Epoch 52/300\n",
            "4620/4620 [==============================] - 1s 227us/step - loss: 0.0771 - acc: 0.9833 - val_loss: 0.1366 - val_acc: 0.9571\n",
            "Epoch 53/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0742 - acc: 0.9840 - val_loss: 0.1397 - val_acc: 0.9556\n",
            "Epoch 54/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0738 - acc: 0.9831 - val_loss: 0.1473 - val_acc: 0.9545\n",
            "Epoch 55/300\n",
            "4620/4620 [==============================] - 1s 227us/step - loss: 0.0738 - acc: 0.9829 - val_loss: 0.1382 - val_acc: 0.9525\n",
            "Epoch 56/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0733 - acc: 0.9833 - val_loss: 0.1426 - val_acc: 0.9540\n",
            "Epoch 57/300\n",
            "2656/4620 [================>.............] - ETA: 0s - loss: 0.0761 - acc: 0.9834"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0727 - acc: 0.9825 - val_loss: 0.1426 - val_acc: 0.9551\n",
            "Epoch 58/300\n",
            "4620/4620 [==============================] - 1s 239us/step - loss: 0.0720 - acc: 0.9855 - val_loss: 0.1482 - val_acc: 0.9495\n",
            "Epoch 59/300\n",
            "4620/4620 [==============================] - 1s 222us/step - loss: 0.0713 - acc: 0.9835 - val_loss: 0.1387 - val_acc: 0.9561\n",
            "Epoch 60/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0701 - acc: 0.9844 - val_loss: 0.1473 - val_acc: 0.9525\n",
            "Epoch 61/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0702 - acc: 0.9864 - val_loss: 0.1403 - val_acc: 0.9581\n",
            "Epoch 62/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0694 - acc: 0.9861 - val_loss: 0.1458 - val_acc: 0.9520\n",
            "Epoch 63/300\n",
            "4620/4620 [==============================] - 1s 231us/step - loss: 0.0693 - acc: 0.9866 - val_loss: 0.1410 - val_acc: 0.9566\n",
            "Epoch 64/300\n",
            "4620/4620 [==============================] - 1s 227us/step - loss: 0.0676 - acc: 0.9848 - val_loss: 0.1363 - val_acc: 0.9576\n",
            "Epoch 65/300\n",
            "2368/4620 [==============>...............] - ETA: 0s - loss: 0.0401 - acc: 0.9903"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 228us/step - loss: 0.0672 - acc: 0.9866 - val_loss: 0.1403 - val_acc: 0.9551\n",
            "Epoch 66/300\n",
            "4620/4620 [==============================] - 1s 231us/step - loss: 0.0674 - acc: 0.9870 - val_loss: 0.1356 - val_acc: 0.9540\n",
            "Epoch 67/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0660 - acc: 0.9874 - val_loss: 0.1428 - val_acc: 0.9545\n",
            "Epoch 68/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0651 - acc: 0.9870 - val_loss: 0.1396 - val_acc: 0.9576\n",
            "Epoch 69/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0653 - acc: 0.9868 - val_loss: 0.1306 - val_acc: 0.9561\n",
            "Epoch 70/300\n",
            "4620/4620 [==============================] - 1s 229us/step - loss: 0.0642 - acc: 0.9866 - val_loss: 0.1411 - val_acc: 0.9520\n",
            "Epoch 71/300\n",
            "4620/4620 [==============================] - 1s 227us/step - loss: 0.0640 - acc: 0.9874 - val_loss: 0.1348 - val_acc: 0.9561\n",
            "Epoch 72/300\n",
            "4620/4620 [==============================] - 1s 229us/step - loss: 0.0627 - acc: 0.9879 - val_loss: 0.1388 - val_acc: 0.9561\n",
            "Epoch 73/300\n",
            "2688/4620 [================>.............] - ETA: 0s - loss: 0.0702 - acc: 0.9859"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 227us/step - loss: 0.0638 - acc: 0.9870 - val_loss: 0.1346 - val_acc: 0.9601\n",
            "Epoch 74/300\n",
            "4620/4620 [==============================] - 1s 237us/step - loss: 0.0631 - acc: 0.9879 - val_loss: 0.1292 - val_acc: 0.9606\n",
            "Epoch 75/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0628 - acc: 0.9872 - val_loss: 0.1353 - val_acc: 0.9556\n",
            "Epoch 76/300\n",
            "4620/4620 [==============================] - 1s 238us/step - loss: 0.0620 - acc: 0.9870 - val_loss: 0.1462 - val_acc: 0.9525\n",
            "Epoch 77/300\n",
            "4620/4620 [==============================] - 1s 237us/step - loss: 0.0612 - acc: 0.9883 - val_loss: 0.1377 - val_acc: 0.9540\n",
            "Epoch 78/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0618 - acc: 0.9861 - val_loss: 0.1320 - val_acc: 0.9601\n",
            "Epoch 79/300\n",
            "4620/4620 [==============================] - 1s 231us/step - loss: 0.0607 - acc: 0.9883 - val_loss: 0.1358 - val_acc: 0.9530\n",
            "Epoch 80/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0602 - acc: 0.9881 - val_loss: 0.1341 - val_acc: 0.9586\n",
            "Epoch 81/300\n",
            "2048/4620 [============>.................] - ETA: 0s - loss: 0.0594 - acc: 0.9888"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0599 - acc: 0.9885 - val_loss: 0.1425 - val_acc: 0.9545\n",
            "Epoch 82/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0597 - acc: 0.9881 - val_loss: 0.1351 - val_acc: 0.9591\n",
            "Epoch 83/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0597 - acc: 0.9881 - val_loss: 0.1422 - val_acc: 0.9540\n",
            "Epoch 84/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0599 - acc: 0.9881 - val_loss: 0.1385 - val_acc: 0.9556\n",
            "Epoch 85/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0577 - acc: 0.9890 - val_loss: 0.1417 - val_acc: 0.9540\n",
            "Epoch 86/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0584 - acc: 0.9892 - val_loss: 0.1393 - val_acc: 0.9535\n",
            "Epoch 87/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0589 - acc: 0.9887 - val_loss: 0.1414 - val_acc: 0.9540\n",
            "Epoch 88/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0574 - acc: 0.9881 - val_loss: 0.1348 - val_acc: 0.9591\n",
            "Epoch 89/300\n",
            "2464/4620 [===============>..............] - ETA: 0s - loss: 0.0607 - acc: 0.9846"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 225us/step - loss: 0.0577 - acc: 0.9874 - val_loss: 0.1348 - val_acc: 0.9556\n",
            "Epoch 90/300\n",
            "4620/4620 [==============================] - 1s 231us/step - loss: 0.0574 - acc: 0.9890 - val_loss: 0.1314 - val_acc: 0.9581\n",
            "Epoch 91/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0570 - acc: 0.9887 - val_loss: 0.1469 - val_acc: 0.9535\n",
            "Epoch 92/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0570 - acc: 0.9879 - val_loss: 0.1309 - val_acc: 0.9591\n",
            "Epoch 93/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0567 - acc: 0.9887 - val_loss: 0.1366 - val_acc: 0.9586\n",
            "Epoch 94/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0563 - acc: 0.9887 - val_loss: 0.1293 - val_acc: 0.9586\n",
            "Epoch 95/300\n",
            "4620/4620 [==============================] - 1s 238us/step - loss: 0.0556 - acc: 0.9903 - val_loss: 0.1320 - val_acc: 0.9591\n",
            "Epoch 96/300\n",
            "4620/4620 [==============================] - 1s 229us/step - loss: 0.0551 - acc: 0.9898 - val_loss: 0.1357 - val_acc: 0.9571\n",
            "Epoch 97/300\n",
            "2048/4620 [============>.................] - ETA: 0s - loss: 0.0464 - acc: 0.9907"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 244us/step - loss: 0.0554 - acc: 0.9898 - val_loss: 0.1383 - val_acc: 0.9556\n",
            "Epoch 98/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0552 - acc: 0.9903 - val_loss: 0.1346 - val_acc: 0.9596\n",
            "Epoch 99/300\n",
            "4620/4620 [==============================] - 1s 237us/step - loss: 0.0546 - acc: 0.9905 - val_loss: 0.1331 - val_acc: 0.9596\n",
            "Epoch 100/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0545 - acc: 0.9894 - val_loss: 0.1320 - val_acc: 0.9606\n",
            "Epoch 101/300\n",
            "4620/4620 [==============================] - 1s 240us/step - loss: 0.0545 - acc: 0.9903 - val_loss: 0.1316 - val_acc: 0.9591\n",
            "Epoch 102/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0539 - acc: 0.9903 - val_loss: 0.1387 - val_acc: 0.9571\n",
            "Epoch 103/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0536 - acc: 0.9894 - val_loss: 0.1370 - val_acc: 0.9530\n",
            "Epoch 104/300\n",
            "4620/4620 [==============================] - 1s 239us/step - loss: 0.0534 - acc: 0.9900 - val_loss: 0.1353 - val_acc: 0.9591\n",
            "Epoch 105/300\n",
            "1792/4620 [==========>...................] - ETA: 0s - loss: 0.0487 - acc: 0.9900"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 240us/step - loss: 0.0529 - acc: 0.9894 - val_loss: 0.1383 - val_acc: 0.9566\n",
            "Epoch 106/300\n",
            "4620/4620 [==============================] - 1s 237us/step - loss: 0.0526 - acc: 0.9903 - val_loss: 0.1334 - val_acc: 0.9601\n",
            "Epoch 107/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0532 - acc: 0.9900 - val_loss: 0.1299 - val_acc: 0.9616\n",
            "Epoch 108/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0528 - acc: 0.9905 - val_loss: 0.1276 - val_acc: 0.9606\n",
            "Epoch 109/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0526 - acc: 0.9909 - val_loss: 0.1359 - val_acc: 0.9586\n",
            "Epoch 110/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0519 - acc: 0.9911 - val_loss: 0.1363 - val_acc: 0.9566\n",
            "Epoch 111/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0523 - acc: 0.9894 - val_loss: 0.1312 - val_acc: 0.9586\n",
            "Epoch 112/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0511 - acc: 0.9909 - val_loss: 0.1288 - val_acc: 0.9606\n",
            "Epoch 113/300\n",
            "2368/4620 [==============>...............] - ETA: 0s - loss: 0.0479 - acc: 0.9928"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0518 - acc: 0.9918 - val_loss: 0.1364 - val_acc: 0.9586\n",
            "Epoch 114/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0514 - acc: 0.9905 - val_loss: 0.1276 - val_acc: 0.9611\n",
            "Epoch 115/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0510 - acc: 0.9909 - val_loss: 0.1301 - val_acc: 0.9611\n",
            "Epoch 116/300\n",
            "4620/4620 [==============================] - 1s 228us/step - loss: 0.0502 - acc: 0.9903 - val_loss: 0.1265 - val_acc: 0.9606\n",
            "Epoch 117/300\n",
            "4620/4620 [==============================] - 1s 231us/step - loss: 0.0511 - acc: 0.9916 - val_loss: 0.1317 - val_acc: 0.9591\n",
            "Epoch 118/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0505 - acc: 0.9903 - val_loss: 0.1315 - val_acc: 0.9591\n",
            "Epoch 119/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0506 - acc: 0.9913 - val_loss: 0.1324 - val_acc: 0.9606\n",
            "Epoch 120/300\n",
            "4620/4620 [==============================] - 1s 231us/step - loss: 0.0498 - acc: 0.9916 - val_loss: 0.1325 - val_acc: 0.9591\n",
            "Epoch 121/300\n",
            "2336/4620 [==============>...............] - ETA: 0s - loss: 0.0687 - acc: 0.9902"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 237us/step - loss: 0.0504 - acc: 0.9911 - val_loss: 0.1347 - val_acc: 0.9586\n",
            "Epoch 122/300\n",
            "4620/4620 [==============================] - 1s 241us/step - loss: 0.0499 - acc: 0.9922 - val_loss: 0.1306 - val_acc: 0.9591\n",
            "Epoch 123/300\n",
            "4620/4620 [==============================] - 1s 239us/step - loss: 0.0501 - acc: 0.9909 - val_loss: 0.1301 - val_acc: 0.9596\n",
            "Epoch 124/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0497 - acc: 0.9916 - val_loss: 0.1282 - val_acc: 0.9616\n",
            "Epoch 125/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0491 - acc: 0.9909 - val_loss: 0.1292 - val_acc: 0.9616\n",
            "Epoch 126/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0493 - acc: 0.9918 - val_loss: 0.1336 - val_acc: 0.9581\n",
            "Epoch 127/300\n",
            "4620/4620 [==============================] - 1s 238us/step - loss: 0.0490 - acc: 0.9911 - val_loss: 0.1383 - val_acc: 0.9566\n",
            "Epoch 128/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0492 - acc: 0.9926 - val_loss: 0.1313 - val_acc: 0.9591\n",
            "Epoch 129/300\n",
            "1600/4620 [=========>....................] - ETA: 0s - loss: 0.0431 - acc: 0.9912"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 237us/step - loss: 0.0488 - acc: 0.9918 - val_loss: 0.1266 - val_acc: 0.9631\n",
            "Epoch 130/300\n",
            "4620/4620 [==============================] - 1s 231us/step - loss: 0.0485 - acc: 0.9922 - val_loss: 0.1330 - val_acc: 0.9616\n",
            "Epoch 131/300\n",
            "4620/4620 [==============================] - 1s 239us/step - loss: 0.0489 - acc: 0.9920 - val_loss: 0.1307 - val_acc: 0.9611\n",
            "Epoch 132/300\n",
            "4620/4620 [==============================] - 1s 238us/step - loss: 0.0486 - acc: 0.9918 - val_loss: 0.1280 - val_acc: 0.9616\n",
            "Epoch 133/300\n",
            "4620/4620 [==============================] - 1s 231us/step - loss: 0.0482 - acc: 0.9911 - val_loss: 0.1291 - val_acc: 0.9616\n",
            "Epoch 134/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0481 - acc: 0.9918 - val_loss: 0.1316 - val_acc: 0.9601\n",
            "Epoch 135/300\n",
            "4620/4620 [==============================] - 1s 229us/step - loss: 0.0486 - acc: 0.9918 - val_loss: 0.1321 - val_acc: 0.9586\n",
            "Epoch 136/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0481 - acc: 0.9920 - val_loss: 0.1376 - val_acc: 0.9586\n",
            "Epoch 137/300\n",
            "2304/4620 [=============>................] - ETA: 0s - loss: 0.0460 - acc: 0.9926"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0478 - acc: 0.9929 - val_loss: 0.1324 - val_acc: 0.9596\n",
            "Epoch 138/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0477 - acc: 0.9913 - val_loss: 0.1319 - val_acc: 0.9591\n",
            "Epoch 139/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0467 - acc: 0.9935 - val_loss: 0.1342 - val_acc: 0.9601\n",
            "Epoch 140/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0475 - acc: 0.9918 - val_loss: 0.1302 - val_acc: 0.9596\n",
            "Epoch 141/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0474 - acc: 0.9920 - val_loss: 0.1361 - val_acc: 0.9606\n",
            "Epoch 142/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0473 - acc: 0.9935 - val_loss: 0.1331 - val_acc: 0.9596\n",
            "Epoch 143/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0468 - acc: 0.9926 - val_loss: 0.1338 - val_acc: 0.9586\n",
            "Epoch 144/300\n",
            "4620/4620 [==============================] - 1s 231us/step - loss: 0.0471 - acc: 0.9920 - val_loss: 0.1337 - val_acc: 0.9596\n",
            "Epoch 145/300\n",
            "2336/4620 [==============>...............] - ETA: 0s - loss: 0.0567 - acc: 0.9914"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 231us/step - loss: 0.0463 - acc: 0.9918 - val_loss: 0.1288 - val_acc: 0.9586\n",
            "Epoch 146/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0468 - acc: 0.9922 - val_loss: 0.1334 - val_acc: 0.9596\n",
            "Epoch 147/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0464 - acc: 0.9926 - val_loss: 0.1342 - val_acc: 0.9601\n",
            "Epoch 148/300\n",
            "4620/4620 [==============================] - 1s 226us/step - loss: 0.0464 - acc: 0.9920 - val_loss: 0.1348 - val_acc: 0.9591\n",
            "Epoch 149/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0462 - acc: 0.9920 - val_loss: 0.1323 - val_acc: 0.9596\n",
            "Epoch 150/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0462 - acc: 0.9922 - val_loss: 0.1319 - val_acc: 0.9626\n",
            "Epoch 151/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0454 - acc: 0.9924 - val_loss: 0.1357 - val_acc: 0.9601\n",
            "Epoch 152/300\n",
            "4620/4620 [==============================] - 1s 229us/step - loss: 0.0455 - acc: 0.9926 - val_loss: 0.1308 - val_acc: 0.9601\n",
            "Epoch 153/300\n",
            "1824/4620 [==========>...................] - ETA: 0s - loss: 0.0543 - acc: 0.9923"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0461 - acc: 0.9926 - val_loss: 0.1305 - val_acc: 0.9611\n",
            "Epoch 154/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0455 - acc: 0.9931 - val_loss: 0.1329 - val_acc: 0.9616\n",
            "Epoch 155/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0457 - acc: 0.9922 - val_loss: 0.1337 - val_acc: 0.9596\n",
            "Epoch 156/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0455 - acc: 0.9931 - val_loss: 0.1329 - val_acc: 0.9606\n",
            "Epoch 157/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0453 - acc: 0.9933 - val_loss: 0.1346 - val_acc: 0.9586\n",
            "Epoch 158/300\n",
            "4620/4620 [==============================] - 1s 238us/step - loss: 0.0451 - acc: 0.9931 - val_loss: 0.1320 - val_acc: 0.9596\n",
            "Epoch 159/300\n",
            "4620/4620 [==============================] - 1s 238us/step - loss: 0.0447 - acc: 0.9935 - val_loss: 0.1350 - val_acc: 0.9601\n",
            "Epoch 160/300\n",
            "4620/4620 [==============================] - 1s 237us/step - loss: 0.0449 - acc: 0.9935 - val_loss: 0.1323 - val_acc: 0.9606\n",
            "Epoch 161/300\n",
            "1344/4620 [=======>......................] - ETA: 0s - loss: 0.0406 - acc: 0.9933"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0451 - acc: 0.9931 - val_loss: 0.1313 - val_acc: 0.9601\n",
            "Epoch 162/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0449 - acc: 0.9926 - val_loss: 0.1290 - val_acc: 0.9611\n",
            "Epoch 163/300\n",
            "4620/4620 [==============================] - 1s 227us/step - loss: 0.0448 - acc: 0.9931 - val_loss: 0.1294 - val_acc: 0.9611\n",
            "Epoch 164/300\n",
            "4620/4620 [==============================] - 1s 228us/step - loss: 0.0447 - acc: 0.9929 - val_loss: 0.1294 - val_acc: 0.9591\n",
            "Epoch 165/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0447 - acc: 0.9931 - val_loss: 0.1274 - val_acc: 0.9616\n",
            "Epoch 166/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0442 - acc: 0.9931 - val_loss: 0.1308 - val_acc: 0.9596\n",
            "Epoch 167/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0446 - acc: 0.9931 - val_loss: 0.1296 - val_acc: 0.9606\n",
            "Epoch 168/300\n",
            "4620/4620 [==============================] - 1s 231us/step - loss: 0.0445 - acc: 0.9933 - val_loss: 0.1332 - val_acc: 0.9601\n",
            "Epoch 169/300\n",
            "2208/4620 [=============>................] - ETA: 0s - loss: 0.0364 - acc: 0.9923"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0443 - acc: 0.9931 - val_loss: 0.1312 - val_acc: 0.9601\n",
            "Epoch 170/300\n",
            "4620/4620 [==============================] - 1s 238us/step - loss: 0.0443 - acc: 0.9929 - val_loss: 0.1336 - val_acc: 0.9591\n",
            "Epoch 171/300\n",
            "4620/4620 [==============================] - 1s 238us/step - loss: 0.0440 - acc: 0.9926 - val_loss: 0.1332 - val_acc: 0.9601\n",
            "Epoch 172/300\n",
            "4620/4620 [==============================] - 1s 240us/step - loss: 0.0435 - acc: 0.9926 - val_loss: 0.1309 - val_acc: 0.9601\n",
            "Epoch 173/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0441 - acc: 0.9929 - val_loss: 0.1328 - val_acc: 0.9606\n",
            "Epoch 174/300\n",
            "4620/4620 [==============================] - 1s 241us/step - loss: 0.0437 - acc: 0.9937 - val_loss: 0.1345 - val_acc: 0.9601\n",
            "Epoch 175/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0438 - acc: 0.9933 - val_loss: 0.1346 - val_acc: 0.9601\n",
            "Epoch 176/300\n",
            "4620/4620 [==============================] - 1s 240us/step - loss: 0.0436 - acc: 0.9939 - val_loss: 0.1368 - val_acc: 0.9576\n",
            "Epoch 177/300\n",
            "1312/4620 [=======>......................] - ETA: 0s - loss: 0.0587 - acc: 0.9909"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 237us/step - loss: 0.0437 - acc: 0.9929 - val_loss: 0.1297 - val_acc: 0.9631\n",
            "Epoch 178/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0437 - acc: 0.9933 - val_loss: 0.1367 - val_acc: 0.9596\n",
            "Epoch 179/300\n",
            "4620/4620 [==============================] - 1s 231us/step - loss: 0.0432 - acc: 0.9933 - val_loss: 0.1352 - val_acc: 0.9581\n",
            "Epoch 180/300\n",
            "4620/4620 [==============================] - 1s 241us/step - loss: 0.0434 - acc: 0.9935 - val_loss: 0.1306 - val_acc: 0.9611\n",
            "Epoch 181/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0429 - acc: 0.9935 - val_loss: 0.1315 - val_acc: 0.9616\n",
            "Epoch 182/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0430 - acc: 0.9937 - val_loss: 0.1363 - val_acc: 0.9586\n",
            "Epoch 183/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0431 - acc: 0.9935 - val_loss: 0.1311 - val_acc: 0.9611\n",
            "Epoch 184/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0433 - acc: 0.9929 - val_loss: 0.1333 - val_acc: 0.9601\n",
            "Epoch 185/300\n",
            "2048/4620 [============>.................] - ETA: 0s - loss: 0.0408 - acc: 0.9937"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 238us/step - loss: 0.0429 - acc: 0.9933 - val_loss: 0.1298 - val_acc: 0.9616\n",
            "Epoch 186/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0431 - acc: 0.9937 - val_loss: 0.1345 - val_acc: 0.9606\n",
            "Epoch 187/300\n",
            "4620/4620 [==============================] - 1s 237us/step - loss: 0.0427 - acc: 0.9939 - val_loss: 0.1340 - val_acc: 0.9596\n",
            "Epoch 188/300\n",
            "4620/4620 [==============================] - 1s 238us/step - loss: 0.0424 - acc: 0.9937 - val_loss: 0.1338 - val_acc: 0.9586\n",
            "Epoch 189/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0426 - acc: 0.9933 - val_loss: 0.1309 - val_acc: 0.9611\n",
            "Epoch 190/300\n",
            "4620/4620 [==============================] - 1s 240us/step - loss: 0.0424 - acc: 0.9929 - val_loss: 0.1327 - val_acc: 0.9606\n",
            "Epoch 191/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0427 - acc: 0.9933 - val_loss: 0.1339 - val_acc: 0.9596\n",
            "Epoch 192/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0426 - acc: 0.9933 - val_loss: 0.1374 - val_acc: 0.9596\n",
            "Epoch 193/300\n",
            "1408/4620 [========>.....................] - ETA: 0s - loss: 0.0678 - acc: 0.9901"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0422 - acc: 0.9929 - val_loss: 0.1321 - val_acc: 0.9611\n",
            "Epoch 194/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0421 - acc: 0.9933 - val_loss: 0.1322 - val_acc: 0.9591\n",
            "Epoch 195/300\n",
            "4620/4620 [==============================] - 1s 237us/step - loss: 0.0422 - acc: 0.9939 - val_loss: 0.1309 - val_acc: 0.9606\n",
            "Epoch 196/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0421 - acc: 0.9942 - val_loss: 0.1335 - val_acc: 0.9596\n",
            "Epoch 197/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0420 - acc: 0.9933 - val_loss: 0.1325 - val_acc: 0.9601\n",
            "Epoch 198/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0422 - acc: 0.9935 - val_loss: 0.1334 - val_acc: 0.9601\n",
            "Epoch 199/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0416 - acc: 0.9939 - val_loss: 0.1334 - val_acc: 0.9601\n",
            "Epoch 200/300\n",
            "4620/4620 [==============================] - 1s 238us/step - loss: 0.0419 - acc: 0.9933 - val_loss: 0.1329 - val_acc: 0.9606\n",
            "Epoch 201/300\n",
            "2016/4620 [============>.................] - ETA: 0s - loss: 0.0322 - acc: 0.9960"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0417 - acc: 0.9946 - val_loss: 0.1365 - val_acc: 0.9596\n",
            "Epoch 202/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0415 - acc: 0.9939 - val_loss: 0.1364 - val_acc: 0.9596\n",
            "Epoch 203/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0416 - acc: 0.9933 - val_loss: 0.1340 - val_acc: 0.9601\n",
            "Epoch 204/300\n",
            "4620/4620 [==============================] - 1s 237us/step - loss: 0.0413 - acc: 0.9942 - val_loss: 0.1369 - val_acc: 0.9601\n",
            "Epoch 205/300\n",
            "4620/4620 [==============================] - 1s 240us/step - loss: 0.0417 - acc: 0.9931 - val_loss: 0.1369 - val_acc: 0.9606\n",
            "Epoch 206/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0413 - acc: 0.9942 - val_loss: 0.1378 - val_acc: 0.9601\n",
            "Epoch 207/300\n",
            "4620/4620 [==============================] - 1s 237us/step - loss: 0.0405 - acc: 0.9935 - val_loss: 0.1373 - val_acc: 0.9586\n",
            "Epoch 208/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0412 - acc: 0.9935 - val_loss: 0.1378 - val_acc: 0.9601\n",
            "Epoch 209/300\n",
            "1728/4620 [==========>...................] - ETA: 0s - loss: 0.0499 - acc: 0.9919"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 241us/step - loss: 0.0412 - acc: 0.9942 - val_loss: 0.1337 - val_acc: 0.9621\n",
            "Epoch 210/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0415 - acc: 0.9937 - val_loss: 0.1346 - val_acc: 0.9606\n",
            "Epoch 211/300\n",
            "4620/4620 [==============================] - 1s 239us/step - loss: 0.0411 - acc: 0.9935 - val_loss: 0.1328 - val_acc: 0.9596\n",
            "Epoch 212/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0409 - acc: 0.9937 - val_loss: 0.1334 - val_acc: 0.9601\n",
            "Epoch 213/300\n",
            "4620/4620 [==============================] - 1s 226us/step - loss: 0.0412 - acc: 0.9933 - val_loss: 0.1353 - val_acc: 0.9586\n",
            "Epoch 214/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0412 - acc: 0.9939 - val_loss: 0.1341 - val_acc: 0.9606\n",
            "Epoch 215/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0412 - acc: 0.9933 - val_loss: 0.1354 - val_acc: 0.9601\n",
            "Epoch 216/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0410 - acc: 0.9942 - val_loss: 0.1355 - val_acc: 0.9596\n",
            "Epoch 217/300\n",
            "2112/4620 [============>.................] - ETA: 0s - loss: 0.0414 - acc: 0.9934"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0408 - acc: 0.9939 - val_loss: 0.1342 - val_acc: 0.9601\n",
            "Epoch 218/300\n",
            "4620/4620 [==============================] - 1s 228us/step - loss: 0.0405 - acc: 0.9939 - val_loss: 0.1336 - val_acc: 0.9611\n",
            "Epoch 219/300\n",
            "4620/4620 [==============================] - 1s 229us/step - loss: 0.0407 - acc: 0.9939 - val_loss: 0.1320 - val_acc: 0.9601\n",
            "Epoch 220/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0402 - acc: 0.9946 - val_loss: 0.1327 - val_acc: 0.9606\n",
            "Epoch 221/300\n",
            "4620/4620 [==============================] - 1s 229us/step - loss: 0.0402 - acc: 0.9944 - val_loss: 0.1356 - val_acc: 0.9601\n",
            "Epoch 222/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0404 - acc: 0.9944 - val_loss: 0.1380 - val_acc: 0.9586\n",
            "Epoch 223/300\n",
            "4620/4620 [==============================] - 1s 225us/step - loss: 0.0408 - acc: 0.9935 - val_loss: 0.1340 - val_acc: 0.9611\n",
            "Epoch 224/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0405 - acc: 0.9939 - val_loss: 0.1357 - val_acc: 0.9601\n",
            "Epoch 225/300\n",
            "2016/4620 [============>.................] - ETA: 0s - loss: 0.0295 - acc: 0.9960"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0406 - acc: 0.9942 - val_loss: 0.1342 - val_acc: 0.9616\n",
            "Epoch 226/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0403 - acc: 0.9937 - val_loss: 0.1364 - val_acc: 0.9611\n",
            "Epoch 227/300\n",
            "4620/4620 [==============================] - 1s 226us/step - loss: 0.0403 - acc: 0.9946 - val_loss: 0.1361 - val_acc: 0.9601\n",
            "Epoch 228/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0403 - acc: 0.9942 - val_loss: 0.1346 - val_acc: 0.9601\n",
            "Epoch 229/300\n",
            "4620/4620 [==============================] - 1s 227us/step - loss: 0.0402 - acc: 0.9942 - val_loss: 0.1350 - val_acc: 0.9611\n",
            "Epoch 230/300\n",
            "4620/4620 [==============================] - 1s 237us/step - loss: 0.0400 - acc: 0.9948 - val_loss: 0.1343 - val_acc: 0.9596\n",
            "Epoch 231/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0402 - acc: 0.9946 - val_loss: 0.1322 - val_acc: 0.9606\n",
            "Epoch 232/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0399 - acc: 0.9939 - val_loss: 0.1331 - val_acc: 0.9606\n",
            "Epoch 233/300\n",
            "2336/4620 [==============>...............] - ETA: 0s - loss: 0.0436 - acc: 0.9944"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0397 - acc: 0.9946 - val_loss: 0.1370 - val_acc: 0.9596\n",
            "Epoch 234/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0397 - acc: 0.9944 - val_loss: 0.1329 - val_acc: 0.9601\n",
            "Epoch 235/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0403 - acc: 0.9942 - val_loss: 0.1376 - val_acc: 0.9596\n",
            "Epoch 236/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0398 - acc: 0.9944 - val_loss: 0.1382 - val_acc: 0.9586\n",
            "Epoch 237/300\n",
            "4620/4620 [==============================] - 1s 227us/step - loss: 0.0399 - acc: 0.9942 - val_loss: 0.1326 - val_acc: 0.9606\n",
            "Epoch 238/300\n",
            "4620/4620 [==============================] - 1s 228us/step - loss: 0.0397 - acc: 0.9946 - val_loss: 0.1328 - val_acc: 0.9611\n",
            "Epoch 239/300\n",
            "4620/4620 [==============================] - 1s 226us/step - loss: 0.0396 - acc: 0.9944 - val_loss: 0.1364 - val_acc: 0.9606\n",
            "Epoch 240/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0395 - acc: 0.9952 - val_loss: 0.1369 - val_acc: 0.9606\n",
            "Epoch 241/300\n",
            "2336/4620 [==============>...............] - ETA: 0s - loss: 0.0125 - acc: 0.9961"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0397 - acc: 0.9937 - val_loss: 0.1360 - val_acc: 0.9586\n",
            "Epoch 242/300\n",
            "4620/4620 [==============================] - 1s 229us/step - loss: 0.0397 - acc: 0.9946 - val_loss: 0.1340 - val_acc: 0.9606\n",
            "Epoch 243/300\n",
            "4620/4620 [==============================] - 1s 237us/step - loss: 0.0395 - acc: 0.9946 - val_loss: 0.1352 - val_acc: 0.9596\n",
            "Epoch 244/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0394 - acc: 0.9950 - val_loss: 0.1336 - val_acc: 0.9611\n",
            "Epoch 245/300\n",
            "4620/4620 [==============================] - 1s 240us/step - loss: 0.0392 - acc: 0.9950 - val_loss: 0.1302 - val_acc: 0.9601\n",
            "Epoch 246/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0397 - acc: 0.9942 - val_loss: 0.1333 - val_acc: 0.9591\n",
            "Epoch 247/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0397 - acc: 0.9944 - val_loss: 0.1321 - val_acc: 0.9611\n",
            "Epoch 248/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0391 - acc: 0.9946 - val_loss: 0.1322 - val_acc: 0.9596\n",
            "Epoch 249/300\n",
            "1824/4620 [==========>...................] - ETA: 0s - loss: 0.0265 - acc: 0.9945"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0390 - acc: 0.9950 - val_loss: 0.1347 - val_acc: 0.9601\n",
            "Epoch 250/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0392 - acc: 0.9952 - val_loss: 0.1357 - val_acc: 0.9586\n",
            "Epoch 251/300\n",
            "4620/4620 [==============================] - 1s 226us/step - loss: 0.0391 - acc: 0.9950 - val_loss: 0.1335 - val_acc: 0.9606\n",
            "Epoch 252/300\n",
            "4620/4620 [==============================] - 1s 221us/step - loss: 0.0387 - acc: 0.9944 - val_loss: 0.1373 - val_acc: 0.9591\n",
            "Epoch 253/300\n",
            "4620/4620 [==============================] - 1s 227us/step - loss: 0.0391 - acc: 0.9950 - val_loss: 0.1331 - val_acc: 0.9586\n",
            "Epoch 254/300\n",
            "4620/4620 [==============================] - 1s 228us/step - loss: 0.0392 - acc: 0.9946 - val_loss: 0.1352 - val_acc: 0.9601\n",
            "Epoch 255/300\n",
            "4620/4620 [==============================] - 1s 238us/step - loss: 0.0392 - acc: 0.9948 - val_loss: 0.1318 - val_acc: 0.9606\n",
            "Epoch 256/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0388 - acc: 0.9946 - val_loss: 0.1358 - val_acc: 0.9591\n",
            "Epoch 257/300\n",
            "2112/4620 [============>.................] - ETA: 0s - loss: 0.0377 - acc: 0.9953"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 231us/step - loss: 0.0388 - acc: 0.9950 - val_loss: 0.1357 - val_acc: 0.9586\n",
            "Epoch 258/300\n",
            "4620/4620 [==============================] - 1s 229us/step - loss: 0.0391 - acc: 0.9942 - val_loss: 0.1330 - val_acc: 0.9601\n",
            "Epoch 259/300\n",
            "4620/4620 [==============================] - 1s 230us/step - loss: 0.0389 - acc: 0.9948 - val_loss: 0.1362 - val_acc: 0.9596\n",
            "Epoch 260/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0389 - acc: 0.9950 - val_loss: 0.1358 - val_acc: 0.9601\n",
            "Epoch 261/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0390 - acc: 0.9942 - val_loss: 0.1351 - val_acc: 0.9596\n",
            "Epoch 262/300\n",
            "4620/4620 [==============================] - 1s 238us/step - loss: 0.0388 - acc: 0.9942 - val_loss: 0.1346 - val_acc: 0.9596\n",
            "Epoch 263/300\n",
            "4620/4620 [==============================] - 1s 242us/step - loss: 0.0388 - acc: 0.9946 - val_loss: 0.1354 - val_acc: 0.9606\n",
            "Epoch 264/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0385 - acc: 0.9952 - val_loss: 0.1342 - val_acc: 0.9596\n",
            "Epoch 265/300\n",
            "2016/4620 [============>.................] - ETA: 0s - loss: 0.0364 - acc: 0.9945"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 237us/step - loss: 0.0384 - acc: 0.9944 - val_loss: 0.1347 - val_acc: 0.9606\n",
            "Epoch 266/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0382 - acc: 0.9950 - val_loss: 0.1349 - val_acc: 0.9586\n",
            "Epoch 267/300\n",
            "4620/4620 [==============================] - 1s 239us/step - loss: 0.0386 - acc: 0.9950 - val_loss: 0.1346 - val_acc: 0.9591\n",
            "Epoch 268/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0388 - acc: 0.9952 - val_loss: 0.1364 - val_acc: 0.9601\n",
            "Epoch 269/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0383 - acc: 0.9946 - val_loss: 0.1335 - val_acc: 0.9606\n",
            "Epoch 270/300\n",
            "4620/4620 [==============================] - 1s 231us/step - loss: 0.0383 - acc: 0.9948 - val_loss: 0.1350 - val_acc: 0.9601\n",
            "Epoch 271/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0383 - acc: 0.9957 - val_loss: 0.1377 - val_acc: 0.9591\n",
            "Epoch 272/300\n",
            "4620/4620 [==============================] - 1s 239us/step - loss: 0.0382 - acc: 0.9950 - val_loss: 0.1377 - val_acc: 0.9581\n",
            "Epoch 273/300\n",
            "1504/4620 [========>.....................] - ETA: 0s - loss: 0.0097 - acc: 0.9973"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 243us/step - loss: 0.0387 - acc: 0.9948 - val_loss: 0.1382 - val_acc: 0.9581\n",
            "Epoch 274/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0382 - acc: 0.9950 - val_loss: 0.1350 - val_acc: 0.9606\n",
            "Epoch 275/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0382 - acc: 0.9952 - val_loss: 0.1345 - val_acc: 0.9601\n",
            "Epoch 276/300\n",
            "4620/4620 [==============================] - 1s 227us/step - loss: 0.0380 - acc: 0.9950 - val_loss: 0.1339 - val_acc: 0.9606\n",
            "Epoch 277/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0381 - acc: 0.9950 - val_loss: 0.1366 - val_acc: 0.9601\n",
            "Epoch 278/300\n",
            "4620/4620 [==============================] - 1s 227us/step - loss: 0.0379 - acc: 0.9957 - val_loss: 0.1354 - val_acc: 0.9601\n",
            "Epoch 279/300\n",
            "4620/4620 [==============================] - 1s 228us/step - loss: 0.0379 - acc: 0.9948 - val_loss: 0.1347 - val_acc: 0.9596\n",
            "Epoch 280/300\n",
            "4620/4620 [==============================] - 1s 227us/step - loss: 0.0380 - acc: 0.9952 - val_loss: 0.1381 - val_acc: 0.9596\n",
            "Epoch 281/300\n",
            "2976/4620 [==================>...........] - ETA: 0s - loss: 0.0344 - acc: 0.9956"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 226us/step - loss: 0.0378 - acc: 0.9950 - val_loss: 0.1366 - val_acc: 0.9596\n",
            "Epoch 282/300\n",
            "4620/4620 [==============================] - 1s 238us/step - loss: 0.0383 - acc: 0.9944 - val_loss: 0.1347 - val_acc: 0.9596\n",
            "Epoch 283/300\n",
            "4620/4620 [==============================] - 1s 231us/step - loss: 0.0377 - acc: 0.9957 - val_loss: 0.1367 - val_acc: 0.9601\n",
            "Epoch 284/300\n",
            "4620/4620 [==============================] - 1s 233us/step - loss: 0.0381 - acc: 0.9946 - val_loss: 0.1359 - val_acc: 0.9606\n",
            "Epoch 285/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0380 - acc: 0.9957 - val_loss: 0.1346 - val_acc: 0.9606\n",
            "Epoch 286/300\n",
            "4620/4620 [==============================] - 1s 231us/step - loss: 0.0378 - acc: 0.9950 - val_loss: 0.1342 - val_acc: 0.9601\n",
            "Epoch 287/300\n",
            "4620/4620 [==============================] - 1s 232us/step - loss: 0.0378 - acc: 0.9961 - val_loss: 0.1361 - val_acc: 0.9606\n",
            "Epoch 288/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0376 - acc: 0.9952 - val_loss: 0.1369 - val_acc: 0.9586\n",
            "Epoch 289/300\n",
            "1984/4620 [===========>..................] - ETA: 0s - loss: 0.0374 - acc: 0.9955"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 240us/step - loss: 0.0378 - acc: 0.9952 - val_loss: 0.1372 - val_acc: 0.9586\n",
            "Epoch 290/300\n",
            "4620/4620 [==============================] - 1s 238us/step - loss: 0.0374 - acc: 0.9952 - val_loss: 0.1371 - val_acc: 0.9601\n",
            "Epoch 291/300\n",
            "4620/4620 [==============================] - 1s 240us/step - loss: 0.0377 - acc: 0.9955 - val_loss: 0.1358 - val_acc: 0.9601\n",
            "Epoch 292/300\n",
            "4620/4620 [==============================] - 1s 242us/step - loss: 0.0378 - acc: 0.9952 - val_loss: 0.1386 - val_acc: 0.9596\n",
            "Epoch 293/300\n",
            "4620/4620 [==============================] - 1s 238us/step - loss: 0.0378 - acc: 0.9950 - val_loss: 0.1354 - val_acc: 0.9601\n",
            "Epoch 294/300\n",
            "4620/4620 [==============================] - 1s 234us/step - loss: 0.0376 - acc: 0.9952 - val_loss: 0.1374 - val_acc: 0.9596\n",
            "Epoch 295/300\n",
            "4620/4620 [==============================] - 1s 235us/step - loss: 0.0375 - acc: 0.9957 - val_loss: 0.1378 - val_acc: 0.9606\n",
            "Epoch 296/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0375 - acc: 0.9950 - val_loss: 0.1358 - val_acc: 0.9606\n",
            "Epoch 297/300\n",
            "1824/4620 [==========>...................] - ETA: 0s - loss: 0.0174 - acc: 0.9984"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0376 - acc: 0.9950 - val_loss: 0.1370 - val_acc: 0.9601\n",
            "Epoch 298/300\n",
            "4620/4620 [==============================] - 1s 239us/step - loss: 0.0375 - acc: 0.9955 - val_loss: 0.1374 - val_acc: 0.9586\n",
            "Epoch 299/300\n",
            "4620/4620 [==============================] - 1s 239us/step - loss: 0.0374 - acc: 0.9961 - val_loss: 0.1368 - val_acc: 0.9596\n",
            "Epoch 300/300\n",
            "4620/4620 [==============================] - 1s 236us/step - loss: 0.0374 - acc: 0.9957 - val_loss: 0.1363 - val_acc: 0.9601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cTIFwyP3XUkc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c3a2485a-3ac2-4e0c-a965-62f03a676bce",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525441094252,
          "user_tz": 180,
          "elapsed": 685,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "score_rms = model2.evaluate(X_test_scaled, Y_test)\n",
        "print(\"Cross entropy loss:\", score_rms[0])\n",
        "print(\"Accuracy: \", score_rms[1])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1980/1980 [==============================] - 0s 66us/step\n",
            "Cross entropy loss: 0.1363242324930851\n",
            "Accuracy:  0.9601010103418369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fs8-hnZpXdiJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "f788d3c5-d239-43d2-fc9e-efcb5a5e466a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525441097923,
          "user_tz": 180,
          "elapsed": 1123,
          "user": {
            "displayName": "Fernanda Weiss",
            "photoUrl": "//lh4.googleusercontent.com/-3fKweTbnlHc/AAAAAAAAAAI/AAAAAAAAAPU/RktnQi93nyI/s50-c-k-no/photo.jpg",
            "userId": "100370788011080686465"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plot(model_fit_rms.history)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA64AAAFMCAYAAADLFeHSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f45b5d5e1d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Ajmb8rcuZVe7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Se ve como con este optimizador se obitene un mejor resultado tanto en el conjunto de prueba, con un accuracy del $96\\%$, como en el conjunto de entrenamiento que se logra un error y función de entrenamiento muy cercana al cero. Se pude apreciar, como este modelo sufre más de overfitting que el modelo anterior."
      ]
    }
  ]
}